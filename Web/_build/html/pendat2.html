
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Data Understanding (Outlier) &#8212; WebStatisku</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'pendat2';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="UTS PENDAT" href="uts.html" />
    <link rel="prev" title="Data UnderStanding" href="pendat1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="WebStatisku - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="WebStatisku - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Selamat Datang Web Statis Penambangan Data
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="pendat1.html">Data UnderStanding</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Data Understanding (Outlier)</a></li>
<li class="toctree-l1"><a class="reference internal" href="uts.html">UTS PENDAT</a></li>
<li class="toctree-l1"><a class="reference internal" href="pendat3.html"><strong>Algoritma <em>K-Means</em></strong></a></li>


<li class="toctree-l1"><a class="reference internal" href="pendat4.html"><strong>FUZZY C-MEANS</strong></a></li>

<li class="toctree-l1"><a class="reference internal" href="pendat5.html">Decision Tree</a></li>
<li class="toctree-l1"><a class="reference internal" href="pendat6.html">Teknik Binning</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fpendat2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/pendat2.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Data Understanding (Outlier)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-outlier">Deteksi Outlier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tahap-deteksi-outlier-dengan-knn">Tahap Deteksi Outlier dengan KNN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">Kesimpulan</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-outlier-factor-lof">Local Outlier Factor (LOF)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tahapan-lof">Tahapan LOF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengitung-manual">Mengitung Manual</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-lof-menggunakan-scikit-learn">Implementasi LOF menggunakan Scikit-Learn</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-knn">Klasifikasi Dengan KNN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memisahkan-outlier-dari-data">Memisahkan Outlier Dari Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menghitung-akurasi">Menghitung Akurasi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi">Visualisasi</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-naive-baiyes">Klasifikasi  Dengan Naive Baiyes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menyiapkan-data">Menyiapkan Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pelatihan-pengujian-dan-evaluasi-model-naive-bayes">Pelatihan, Pengujian, dan Evaluasi Model Naïve Bayes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi-confussion-matrix">Visualisasi Confussion Matrix</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="data-understanding-outlier">
<h1>Data Understanding (Outlier)<a class="headerlink" href="#data-understanding-outlier" title="Link to this heading">#</a></h1>
<section id="deteksi-outlier">
<h2>Deteksi Outlier<a class="headerlink" href="#deteksi-outlier" title="Link to this heading">#</a></h2>
<p>Outlier adalah data yang berbeda jauh dari pola umum dalam dataset. Penyebabnya bisa karena kesalahan pengukuran, input data yang salah, atau fenomena unik. Outlier bisa memengaruhi hasil analisis dan model machine learning, sehingga perlu dideteksi.</p>
</section>
<section id="k-nearest-neighbors-knn">
<h2>K-Nearest Neighbors (KNN)<a class="headerlink" href="#k-nearest-neighbors-knn" title="Link to this heading">#</a></h2>
<p>KNN bekerja dengan melihat kedekatan antar data. Dalam deteksi outlier, KNN mengukur jarak antara suatu titik dengan tetangga terdekatnya:</p>
<ul class="simple">
<li><p>Jika suatu titik hanya memiliki sedikit tetangga dalam radius tertentu, kemungkinan besar itu outlier.</p></li>
<li><p>Jika jarak ke tetangga terdekat sangat besar, titik tersebut bisa dianggap sebagai outlier.</p></li>
</ul>
<section id="tahap-deteksi-outlier-dengan-knn">
<h3>Tahap Deteksi Outlier dengan KNN<a class="headerlink" href="#tahap-deteksi-outlier-dengan-knn" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Menghitung Jarak Antar Titik</p></li>
</ol>
<ul class="simple">
<li><p>Menggunakan metrik jarak seperti Euclidean, Manhattan, atau Minkowski untuk mengukur kedekatan antar data.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Menentukan Nilai K (Jumlah Tetangga Terdekat)</p></li>
</ol>
<ul class="simple">
<li><p>K terlalu kecil: terlalu sensitif terhadap noise.</p></li>
<li><p>K terlalu besar: kurang akurat dalam mendeteksi outlier.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Menentukan Skor Outlier</p></li>
</ol>
<ul class="simple">
<li><p>K-Nearest Neighbor Distance: Jika jarak ke K tetangga terlalu besar, kemungkinan outlier.</p></li>
<li><p>Local Outlier Factor (LOF): Membandingkan kepadatan suatu titik dengan tetangganya. Jika kepadatannya lebih rendah, kemungkinan outlier.</p></li>
<li><p>Distance-Based Outlier Score: Jika jumlah tetangga dalam radius tertentu sangat sedikit, bisa dianggap outlier.</p></li>
</ul>
</section>
<section id="kesimpulan">
<h3>Kesimpulan<a class="headerlink" href="#kesimpulan" title="Link to this heading">#</a></h3>
<p>KNN bisa digunakan untuk mendeteksi outlier dengan menganalisis jarak antara titik data dan tetangganya. Metode seperti K-Nearest Neighbor Distance dan LOF membantu mengidentifikasi data yang berbeda jauh dari pola umum. Pemilihan K dan metrik jarak yang tepat sangat penting untuk akurasi deteksi outlier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">pymysql</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>

<span class="c1"># ✅ Fungsi untuk mengambil data dari PostgreSQL</span>
<span class="k">def</span> <span class="nf">get_pg_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;pg-29vania-vaniaptr008-f94a.k.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_jN7GWD4QIOAFWBZiFM2&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">12525</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM iris_postgresql&quot;</span><span class="p">)</span>  <span class="c1"># Pastikan tabel ini ada!</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># ✅ Fungsi untuk mengambil data dari MySQL</span>
<span class="k">def</span> <span class="nf">get_mysql_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;mysql-25907135-mysqql.h.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_-_iUzbq84ojauwfvOBS&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">12005</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM iris_mysql&quot;</span><span class="p">)</span>  <span class="c1"># Pastikan tabel ini ada!</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># ✅ Ambil data dari kedua database</span>
<span class="n">df_postgresql</span> <span class="o">=</span> <span class="n">get_pg_data</span><span class="p">()</span>
<span class="n">df_mysql</span> <span class="o">=</span> <span class="n">get_mysql_data</span><span class="p">()</span>

<span class="c1"># ✅ Gabungkan berdasarkan kolom &#39;id&#39; &amp; &#39;class&#39;</span>
<span class="n">df_merged</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_mysql</span><span class="p">,</span> <span class="n">df_postgresql</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;inner&quot;</span><span class="p">)</span>

<span class="c1"># ✅ Ambil data fitur numerik</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal_width&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_width&quot;</span><span class="p">]</span>
<span class="n">data_values</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># ✅ Fungsi KNN Outlier Detection</span>
<span class="k">def</span> <span class="nf">knn_outlier_detection</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">90</span><span class="p">):</span>
    <span class="n">neigh</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">distances</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">avg_distances</span> <span class="o">=</span> <span class="n">distances</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Ambil jarak k-terjauh sebagai skor</span>
    <span class="k">return</span> <span class="n">avg_distances</span>

<span class="c1"># ✅ Hitung K-NN distance</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">knn_outlier_detection</span><span class="p">(</span><span class="n">data_values</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>

<span class="c1"># ✅ Tentukan threshold sebagai nilai rata-rata + 2 standar deviasi</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier_knn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span>

<span class="c1"># ✅ Hapus data outlier</span>
<span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="o">~</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier_knn&quot;</span><span class="p">]]</span>

<span class="c1"># ✅ Cetak hasil setelah outlier dihapus</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_filtered</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah data setelah outlier dihapus: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_filtered</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># ✅ Visualisasi setelah outlier dihapus</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;sepal_length&quot;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;sepal_width&quot;</span><span class="p">],</span>
    <span class="n">hue</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;deep&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Data Sepal setelah Outlier Dihapus&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;petal_width&quot;</span><span class="p">],</span>
    <span class="n">hue</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;deep&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Data Petal setelah Outlier Dihapus&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> id           class  petal_length  petal_width  sepal_length  sepal_width  knn_distance  outlier_knn
  1     Iris-setosa          14.0          2.0          51.0         35.0     56.510530        False
  2     Iris-setosa          14.0          2.0          49.0         30.0     52.205172        False
  3     Iris-setosa          13.0          2.0          47.0         32.0     51.482230        False
  4     Iris-setosa          15.0          2.0          46.0         31.0     50.519501        False
  5     Iris-setosa          14.0          2.0           5.0         36.0     34.915326        False
  6     Iris-setosa           1.7          0.4           5.4          3.9      3.845777        False
  7     Iris-setosa           1.4          0.3           4.6          3.4      4.228475        False
  8     Iris-setosa           1.5          0.2           5.0          3.4      4.060788        False
  9     Iris-setosa           1.4          0.2           4.4          2.9      4.302325        False
 11     Iris-setosa           1.5          0.2           5.4          3.7      4.033609        False
 12     Iris-setosa           1.6          0.2           4.8          3.4      4.023680        False
 13     Iris-setosa           1.4          0.1           4.8          3.0      4.198809        False
 14     Iris-setosa           1.1          0.1           4.3          3.0      4.631414        False
 15     Iris-setosa           1.2          0.2           5.8         40.0     37.421651        False
 16     Iris-setosa           1.5          0.4           5.7          4.4      4.113393        False
 17     Iris-setosa           1.3          0.4           5.4          3.9      4.203570        False
 18     Iris-setosa           1.4          0.3           5.1          3.5      4.102438        False
 19     Iris-setosa           1.7          0.3           5.7          3.8      3.806573        False
 20     Iris-setosa           1.5          0.3          51.0          3.8     45.600658        False
 21     Iris-setosa           1.7          0.2           5.4          3.4      3.797368        False
 22     Iris-setosa           1.5          0.4           5.1          3.7      4.026164        False
 23     Iris-setosa           1.0          0.2           4.6          3.6      4.641121        False
 24     Iris-setosa           1.7          0.5           5.1          3.3      3.738984        False
 25     Iris-setosa           1.9          0.2           4.8         34.0     31.406528        False
 26     Iris-setosa           1.6          0.2           5.0          3.0      3.942081        False
 27     Iris-setosa           1.6          0.4           5.0          3.4      3.896152        False
 28     Iris-setosa           1.5          0.2           5.2          3.5      4.032369        False
 29     Iris-setosa           1.4          0.2           5.2          3.4      4.110961        False
 31     Iris-setosa           1.6          0.2           4.8          3.1      3.996248        False
 32     Iris-setosa           1.5          0.4           5.4          3.4      3.915354        False
 33     Iris-setosa           1.5          0.1           5.2          4.1      4.220190        False
 34     Iris-setosa           1.4          0.2           5.5          4.2      4.240283        False
 36     Iris-setosa           1.2          0.2           5.0          3.2      4.315090        False
 37     Iris-setosa           1.3          0.2           5.5          3.5      4.158125        False
 38     Iris-setosa           1.5          0.1           4.9          3.1      4.106093        False
 39     Iris-setosa           1.3          0.2           4.4          3.0      4.387482        False
 40     Iris-setosa           1.5          0.2           5.1          3.4      4.039802        False
 41     Iris-setosa           1.3          0.3           5.0          3.5      4.215448        False
 42     Iris-setosa           1.3          0.3           4.5          2.3      4.341659        False
 43     Iris-setosa           1.3          0.2           4.4          3.2      4.402272        False
 44     Iris-setosa           1.6          0.6           5.0          3.5      3.858756        False
 45     Iris-setosa           1.9          0.4           5.1          3.8      3.701351        False
 46     Iris-setosa           1.4          0.3           4.8          3.0      4.112177        False
 47     Iris-setosa           1.6          0.2           5.1          3.8      4.028647        False
 48     Iris-setosa           1.4          0.2           4.6          3.2      4.240283        False
 49     Iris-setosa           1.5          0.2           5.3          3.7      4.050926        False
 50     Iris-setosa           1.4          0.2           5.0          3.3      4.141256        False
 56 Iris-versicolor           4.5          1.3           5.7          2.8      3.203123        False
 57 Iris-versicolor           4.7          1.6           6.3          3.3      3.535534        False
 58 Iris-versicolor           3.3          1.0           4.9          2.4      2.619160        False
 59 Iris-versicolor           4.6          1.3           6.6          2.9      3.522783        False
 60 Iris-versicolor           3.9          1.4           5.2          2.7      2.787472        False
 61 Iris-versicolor           3.5          1.0           5.0          2.0      2.760435        False
 62 Iris-versicolor           4.2          1.5           5.9          3.0      3.109662        False
 63 Iris-versicolor           4.0          1.0           6.0          2.2      3.046309        False
 64 Iris-versicolor           4.7          1.4           6.1          2.9      3.461214        False
 65 Iris-versicolor           3.6          1.3           5.6          2.9      2.539685        False
 66 Iris-versicolor           4.4          1.4           6.7          3.1      3.395585        False
 67 Iris-versicolor           4.5          1.5           5.6          3.0      3.226453        False
 68 Iris-versicolor           4.1          1.0           5.8          2.7      2.920616        False
 69 Iris-versicolor           4.5          1.5           6.2          2.2      3.514257        False
 70 Iris-versicolor           3.9          1.1           5.6          2.5      2.789265        False
 71 Iris-versicolor           4.8          1.8           5.9          3.2      3.612478        False
 72 Iris-versicolor           4.0          1.3           6.1          2.8      2.959730        False
 73 Iris-versicolor           4.9          1.5           6.3          2.5      3.793415        False
 74 Iris-versicolor           4.7          1.2           6.1          2.8      3.424909        False
 75 Iris-versicolor           4.3          1.3           6.4          2.9      3.178050        False
 76 Iris-versicolor           4.4          1.4           6.6          3.0      3.360060        False
 77 Iris-versicolor           4.8          1.4           6.8          2.8      3.822303        False
 78 Iris-versicolor           5.0          1.7           6.7          3.0      3.988734        False
 79 Iris-versicolor           4.5          1.5           6.0          2.9      3.289377        False
 80 Iris-versicolor           3.5          1.0           5.7          2.6      2.487971        False
 81 Iris-versicolor           3.8          1.1           5.5          2.4      2.762245        False
 82 Iris-versicolor           3.7          1.0           5.5          2.4      2.673948        False
 83 Iris-versicolor           3.9          1.2           5.8          2.7      2.810694        False
 84 Iris-versicolor           5.1          1.6           6.0          2.7      3.896152        False
 85 Iris-versicolor           4.5          1.5           5.4          3.0      3.235738        False
 86 Iris-versicolor           4.5          1.6           6.0          3.4      3.286335        False
 87 Iris-versicolor           4.7          1.5           6.7          3.1      3.670150        False
 88 Iris-versicolor           4.4          1.3           6.3          2.3      3.385262        False
 89 Iris-versicolor           4.1          1.3           5.6          3.0      2.891366        False
 90 Iris-versicolor           4.0          1.3           5.5          2.5      2.918904        False
 91 Iris-versicolor           4.4          1.2           5.5          2.6      3.195309        False
 92 Iris-versicolor           4.6          1.4           6.1          3.0      3.355592        False
 93 Iris-versicolor           4.0          1.2           5.8          2.6      2.918904        False
 94 Iris-versicolor           3.3          1.0           5.0          2.3      2.600000        False
 95 Iris-versicolor           4.2          1.3           5.6          2.7      3.039737        False
 96 Iris-versicolor           4.2          1.2           5.7          3.0      2.963106        False
 97 Iris-versicolor           4.2          1.3           5.7          2.9      3.016621        False
 98 Iris-versicolor           4.3          1.3           6.2          2.9      3.128898        False
 99 Iris-versicolor           3.0          1.1           5.1          2.5      2.469818        False
100 Iris-versicolor           4.1          1.3           5.7          2.8      2.951271        False
106  Iris-virginica           6.6          2.1           7.6          3.0      5.853204        False
107  Iris-virginica           4.5          1.7           4.9          2.5      3.452535        False
108  Iris-virginica           6.3          1.8           7.3          2.9      5.401852        False
109  Iris-virginica           5.8          1.8           6.7          2.5      4.792703        False
110  Iris-virginica           6.1          2.5           7.2          3.6      5.358171        False
111  Iris-virginica           5.1          2.0           6.5          3.2      4.095119        False
112  Iris-virginica           5.3          1.9           6.4          2.7      4.263801        False
113  Iris-virginica           5.5          2.1           6.8          3.0      4.583667        False
114  Iris-virginica           5.0          2.0           5.7          2.5      3.937004        False
115  Iris-virginica           5.1         42.0           5.8          2.8     41.740747        False
116  Iris-virginica           5.3          2.3           6.4          3.2      4.369210        False
117  Iris-virginica           5.5          1.8           6.5          3.0      4.396590        False
118  Iris-virginica           6.7          2.2           7.7          3.8      5.977458        False
119  Iris-virginica           6.9          2.3           7.7          2.6      6.251400        False
120  Iris-virginica          50.0          1.5           6.0          2.2     48.336115        False
121  Iris-virginica           5.7          2.3           6.9          3.2      4.851804        False
122  Iris-virginica           4.9          2.0           5.6          2.8      3.764306        False
123  Iris-virginica           6.7          2.0           7.7          2.8      5.979130        False
124  Iris-virginica           4.9          1.8           6.3          2.7      3.849675        False
125  Iris-virginica           5.7          2.1           6.7          3.3      4.714870        False
126  Iris-virginica           6.0         18.0           7.2          3.2     18.256232        False
127  Iris-virginica           4.8          1.8           6.2          2.8      3.721559        False
128  Iris-virginica           4.9          1.8           6.1          3.0      3.764306        False
129  Iris-virginica           5.6          2.1           6.4          2.8      4.589118        False
130  Iris-virginica          58.0          1.6           7.2          3.0     56.157813        False
131  Iris-virginica           6.1          1.9           7.4          2.8      5.309426        False
132  Iris-virginica           6.4          2.0           7.9          3.8      5.742822        False
133  Iris-virginica           5.6          2.2           6.4          2.8      4.627094        False
134  Iris-virginica           5.1          1.5           6.3          2.8      3.916631        False
135  Iris-virginica           5.6         41.0           6.1          2.6     40.798162        False
136  Iris-virginica           6.1          2.3           7.7          3.0      5.538953        False
137  Iris-virginica           5.6          2.4           6.3          3.4      4.649731        False
138  Iris-virginica           5.5          1.8           6.4          3.1      4.364631        False
139  Iris-virginica           4.8          1.8           6.0          3.0      3.655133        False
140  Iris-virginica          45.0          2.1           6.9          3.1     43.366692        False
141  Iris-virginica           5.6          2.4           6.7          3.1      4.752894        False
142  Iris-virginica           5.1          2.3           6.9          3.1      4.348563        False
143  Iris-virginica           5.1          1.9           5.8          2.7      3.953479        False
144  Iris-virginica           5.9          2.3           6.8          3.2      4.996999        False
145  Iris-virginica           5.7         25.0           6.7          3.3     24.948146        False
146  Iris-virginica           5.2          2.3           6.7          3.0      4.376071        False
147  Iris-virginica           5.0          1.9           6.3          2.5      4.014972        False
148  Iris-virginica           5.2          2.0           6.5          3.0      4.197618        False
149  Iris-virginica           5.4          2.3           6.2          3.4      4.411349        False
150  Iris-virginica           5.1          1.8           5.9          3.0      3.896152        False

Jumlah data setelah outlier dihapus: 137
</pre></div>
</div>
<img alt="_images/fc66ab859069acfda6aa309bc3ca6c284ef4a160eea60d730a90fa75f95d7571.png" src="_images/fc66ab859069acfda6aa309bc3ca6c284ef4a160eea60d730a90fa75f95d7571.png" />
<img alt="_images/0dc18a371dc58bc3c9fa0274a301af8d5677fd18f8868f50976301c02db1f867.png" src="_images/0dc18a371dc58bc3c9fa0274a301af8d5677fd18f8868f50976301c02db1f867.png" />
</div>
</div>
<p>Kode ini mengambil data dari PostgreSQL dan MySQL, lalu menggabungkannya berdasarkan kolom “id” dan “class”. Setelah itu, dilakukan deteksi outlier menggunakan K-Nearest Neighbors (KNN) dengan menghitung jarak rata-rata ke 90 tetangga terdekat, kemudian data dengan jarak di atas rata-rata plus 2 standar deviasi dianggap outlier dan dihapus. Terakhir, hasil data yang telah dibersihkan divisualisasikan dalam scatter plot berdasarkan fitur sepal dan petal untuk melihat perbedaan sebelum dan sesudah penghapusan outlier.</p>
</section>
</section>
<section id="local-outlier-factor-lof">
<h2>Local Outlier Factor (LOF)<a class="headerlink" href="#local-outlier-factor-lof" title="Link to this heading">#</a></h2>
<p>Local Outlier Factor (LOF) adalah metode berbasis kepadatan yang digunakan untuk mengidentifikasi outlier dalam suatu dataset. LOF membandingkan kepadatan lokal suatu titik dengan kepadatan lokal dari tetangganya. Jika suatu titik memiliki kepadatan yang jauh lebih rendah dibandingkan dengan sekitarnya, maka titik tersebut dianggap sebagai outlier.</p>
<p>LOF mengukur sejauh mana suatu titik berbeda dari tetangganya dalam hal kepadatan. Metode ini berguna dalam mendeteksi outlier karena tidak hanya mempertimbangkan jarak absolut, tetapi juga pola kepadatan lokal. LOF memberikan skor, di mana nilai lebih tinggi menunjukkan bahwa titik tersebut lebih mungkin menjadi outlier.</p>
<section id="tahapan-lof">
<h3>Tahapan LOF<a class="headerlink" href="#tahapan-lof" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Menentukan jumlah tetangga (k-nearest neighbors, k): LOF membutuhkan parameter k yang menentukan jumlah tetangga yang akan dianalisis untuk setiap titik.</p></li>
<li><p>Menghitung jarak k-tetangga terdekat: Untuk setiap titik, dihitung jarak ke k tetangga terdekatnya.</p></li>
<li><p>Menentukan kepadatan lokal: Kepadatan lokal dihitung berdasarkan jarak rata-rata ke tetangga terdekat.</p></li>
<li><p>Menghitung LOF score: Perbandingan kepadatan lokal titik dengan kepadatan lokal dari tetangga-tetangganya digunakan untuk menentukan apakah suatu titik adalah outlier.</p></li>
<li><p>Menentukan threshold outlier: Biasanya, nilai LOF yang lebih tinggi dari ambang batas tertentu dianggap sebagai outlier.</p></li>
</ol>
</section>
<section id="mengitung-manual">
<h3>Mengitung Manual<a class="headerlink" href="#mengitung-manual" title="Link to this heading">#</a></h3>
<p>Sebagai contoh, kita akan menghitung LOF secara manual menggunakan dataset kecil yang terdiri dari 10 baris dengan 2 fitur:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Feature 1</p></th>
<th class="head"><p>Feature 2</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>2.0</p></td>
<td><p>3.0</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>2.5</p></td>
<td><p>3.2</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>2.2</p></td>
<td><p>3.1</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>8.0</p></td>
<td><p>9.0</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>2.1</p></td>
<td><p>3.0</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>2.3</p></td>
<td><p>3.2</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p>8.1</p></td>
<td><p>9.2</p></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p>2.4</p></td>
<td><p>3.3</p></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><p>2.6</p></td>
<td><p>3.4</p></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><p>7.9</p></td>
<td><p>9.1</p></td>
</tr>
</tbody>
</table>
</div>
<p>Misalkan kita ingin menghitung LOF untuk titik <strong>ID = 3 (2.2, 3.1)</strong>.</p>
<ol class="arabic">
<li><p><strong>Hitung Jarak Euclidean ke Tetangga Terdekat</strong>:</p>
<ul class="simple">
<li><p>Ke titik 5 (2.1, 3.0): 0.14</p></li>
<li><p>Ke titik 6 (2.3, 3.2): 0.14</p></li>
<li><p>Ke titik 2 (2.5, 3.2): 0.31</p></li>
</ul>
</li>
<li><p><strong>Tentukan k-Tetangga Terdekat (k=3)</strong>:</p>
<ul class="simple">
<li><p>Tetangga terdekat: titik 5, 6, dan 2.</p></li>
</ul>
</li>
<li><p><strong>Hitung Reachability Distance</strong>:</p>
<ul class="simple">
<li><p>Reachability distance dihitung sebagai maksimum antara jarak Euclidean dan jarak k-neighbor.</p></li>
<li><p>rD(3,5) = max(0.14, 0.31) = 0.31</p></li>
<li><p>rD(3,6) = max(0.14, 0.31) = 0.31</p></li>
<li><p>rD(3,2) = max(0.31, 0.31) = 0.31</p></li>
</ul>
</li>
<li><p><strong>Hitung Local Reachability Density (LRD)</strong>:</p>
<p><img alt="image.png" src="_images/image1.png" /></p>
</li>
<li><p><strong>Hitung LOF</strong>:</p></li>
</ol>
<p><img alt="image.png" src="_images/image2.png" /></p>
<ol class="arabic simple" start="7">
<li><p><strong>Interpretasi</strong>:</p>
<ul class="simple">
<li><p>Karena <strong>LOF &lt; 1</strong>, titik <strong>ID = 3</strong> bukan outlier.</p></li>
<li><p>Jika LOF jauh lebih besar dari 1, titik akan dianggap outlier.</p></li>
</ul>
</li>
</ol>
</section>
<section id="implementasi-lof-menggunakan-scikit-learn">
<h3>Implementasi LOF menggunakan Scikit-Learn<a class="headerlink" href="#implementasi-lof-menggunakan-scikit-learn" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Feature 1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">8.1</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mf">2.6</span><span class="p">,</span> <span class="mf">7.9</span><span class="p">],</span>
    <span class="s2">&quot;Feature 2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">,</span> <span class="mf">9.2</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">,</span> <span class="mf">3.4</span><span class="p">,</span> <span class="mf">9.1</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Model LOF</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;LOF Label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Menampilkan jumlah outlier</span>
<span class="n">num_outliers</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;LOF Label&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah outlier: </span><span class="si">{</span><span class="n">num_outliers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menampilkan data outlier</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOF Label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data Outlier:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outliers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah outlier: 3

Data Outlier:
   Feature 1  Feature 2  LOF Label
3        8.0        9.0         -1
6        8.1        9.2         -1
9        7.9        9.1         -1
</pre></div>
</div>
</div>
</div>
<p>Kode di atas menggunakan metode <strong>Local Outlier Factor (LOF)</strong> dari pustaka <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> untuk mendeteksi <strong>outlier</strong> dalam dataset. Dataset terdiri dari dua fitur dengan 10 sampel yang disimpan dalam bentuk <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>. Model LOF dibuat dengan mempertimbangkan <strong>3 tetangga terdekat</strong> (<code class="docutils literal notranslate"><span class="pre">n_neighbors=3</span></code>) untuk menghitung kepadatan lokal setiap titik. Hasil perhitungan LOF mengembalikan label <code class="docutils literal notranslate"><span class="pre">1</span></code> untuk data normal dan <code class="docutils literal notranslate"><span class="pre">-1</span></code> untuk data yang dianggap <strong>outlier</strong>. Setelah itu, kode menghitung jumlah outlier dan menampilkan daftar sampel yang terdeteksi sebagai <strong>outlier</strong> berdasarkan skor LOF. Dengan pendekatan ini, kita dapat mengidentifikasi data yang berbeda secara signifikan dari sekitarnya, yang berguna dalam <strong>analisis data</strong> dan <strong>pembersihan dataset</strong>.</p>
</section>
</section>
<section id="klasifikasi-dengan-knn">
<h2>Klasifikasi Dengan KNN<a class="headerlink" href="#klasifikasi-dengan-knn" title="Link to this heading">#</a></h2>
<section id="memisahkan-outlier-dari-data">
<h3>Memisahkan Outlier Dari Data<a class="headerlink" href="#memisahkan-outlier-dari-data" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">pymysql</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>

<span class="c1"># ✅ Fungsi untuk mengambil data dari PostgreSQL</span>
<span class="k">def</span> <span class="nf">get_pg_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;pg-29vania-vaniaptr008-f94a.k.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_jN7GWD4QIOAFWBZiFM2&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">12525</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM iris_postgresql&quot;</span><span class="p">)</span>  <span class="c1"># Pastikan tabel ini ada!</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># ✅ Fungsi untuk mengambil data dari MySQL</span>
<span class="k">def</span> <span class="nf">get_mysql_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;mysql-25907135-mysqql.h.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_-_iUzbq84ojauwfvOBS&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">12005</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM iris_mysql&quot;</span><span class="p">)</span>  <span class="c1"># Pastikan tabel ini ada!</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># ✅ Ambil data dari kedua database</span>
<span class="n">df_postgresql</span> <span class="o">=</span> <span class="n">get_pg_data</span><span class="p">()</span>
<span class="n">df_mysql</span> <span class="o">=</span> <span class="n">get_mysql_data</span><span class="p">()</span>

<span class="c1"># Gabungkan berdasarkan kolom &#39;id&#39; dan &#39;class&#39;</span>
<span class="n">df_merge</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_mysql</span><span class="p">,</span> <span class="n">df_postgresql</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;inner&quot;</span><span class="p">)</span>

<span class="c1"># Ambil data fitur numerik tanpa kolom &#39;class&#39;</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal_width&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_width&quot;</span><span class="p">]</span>
<span class="n">data_values</span> <span class="o">=</span> <span class="n">df_merge</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Inisialisasi model LOF</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">data_values</span><span class="p">)</span>

<span class="c1"># Tambahkan hasil label ke dataframe</span>
<span class="n">df_merge</span><span class="p">[</span><span class="s2">&quot;outlier_label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">label</span>

<span class="c1"># Cetak hasil dengan ID dan class</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_merge</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="n">num_outliers</span> <span class="o">=</span> <span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah outlier: </span><span class="si">{</span><span class="n">num_outliers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df_merge</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier_label&quot;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">df_merge</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier_label&quot;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data Outlier:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outliers</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah data setelah dihapus : &quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_filtered</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data tidak outlier :&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_filtered</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> id           class  petal_length  petal_width  sepal_length  sepal_width  outlier_label
  1     Iris-setosa          14.0          2.0          51.0         35.0             -1
  2     Iris-setosa          14.0          2.0          49.0         30.0             -1
  3     Iris-setosa          13.0          2.0          47.0         32.0             -1
  4     Iris-setosa          15.0          2.0          46.0         31.0             -1
  5     Iris-setosa          14.0          2.0           5.0         36.0             -1
  6     Iris-setosa           1.7          0.4           5.4          3.9              1
  7     Iris-setosa           1.4          0.3           4.6          3.4              1
  8     Iris-setosa           1.5          0.2           5.0          3.4              1
  9     Iris-setosa           1.4          0.2           4.4          2.9              1
 10     Iris-setosa           1.5          0.1          94.0          3.1             -1
 11     Iris-setosa           1.5          0.2           5.4          3.7              1
 12     Iris-setosa           1.6          0.2           4.8          3.4              1
 13     Iris-setosa           1.4          0.1           4.8          3.0              1
 14     Iris-setosa           1.1          0.1           4.3          3.0              1
 15     Iris-setosa           1.2          0.2           5.8         40.0             -1
 16     Iris-setosa           1.5          0.4           5.7          4.4              1
 17     Iris-setosa           1.3          0.4           5.4          3.9              1
 18     Iris-setosa           1.4          0.3           5.1          3.5              1
 19     Iris-setosa           1.7          0.3           5.7          3.8              1
 20     Iris-setosa           1.5          0.3          51.0          3.8             -1
 21     Iris-setosa           1.7          0.2           5.4          3.4              1
 22     Iris-setosa           1.5          0.4           5.1          3.7              1
 23     Iris-setosa           1.0          0.2           4.6          3.6              1
 24     Iris-setosa           1.7          0.5           5.1          3.3              1
 25     Iris-setosa           1.9          0.2           4.8         34.0             -1
 26     Iris-setosa           1.6          0.2           5.0          3.0              1
 27     Iris-setosa           1.6          0.4           5.0          3.4              1
 28     Iris-setosa           1.5          0.2           5.2          3.5              1
 29     Iris-setosa           1.4          0.2           5.2          3.4              1
 30     Iris-setosa           1.6          0.2          74.0          3.2             -1
 31     Iris-setosa           1.6          0.2           4.8          3.1              1
 32     Iris-setosa           1.5          0.4           5.4          3.4              1
 33     Iris-setosa           1.5          0.1           5.2          4.1              1
 34     Iris-setosa           1.4          0.2           5.5          4.2              1
 35     Iris-setosa           1.5          0.1           4.9         94.0             -1
 36     Iris-setosa           1.2          0.2           5.0          3.2              1
 37     Iris-setosa           1.3          0.2           5.5          3.5              1
 38     Iris-setosa           1.5          0.1           4.9          3.1              1
 39     Iris-setosa           1.3          0.2           4.4          3.0              1
 40     Iris-setosa           1.5          0.2           5.1          3.4              1
 41     Iris-setosa           1.3          0.3           5.0          3.5              1
 42     Iris-setosa           1.3          0.3           4.5          2.3              1
 43     Iris-setosa           1.3          0.2           4.4          3.2              1
 44     Iris-setosa           1.6          0.6           5.0          3.5              1
 45     Iris-setosa           1.9          0.4           5.1          3.8              1
 46     Iris-setosa           1.4          0.3           4.8          3.0              1
 47     Iris-setosa           1.6          0.2           5.1          3.8              1
 48     Iris-setosa           1.4          0.2           4.6          3.2              1
 49     Iris-setosa           1.5          0.2           5.3          3.7              1
 50     Iris-setosa           1.4          0.2           5.0          3.3              1
 51 Iris-versicolor          47.0         14.0          70.0         32.0             -1
 52 Iris-versicolor          45.0         15.0          64.0         32.0             -1
 53 Iris-versicolor          49.0         15.0          69.0         31.0             -1
 54 Iris-versicolor          40.0         13.0          55.0         23.0             -1
 55 Iris-versicolor          46.0         15.0          65.0         28.0             -1
 56 Iris-versicolor           4.5          1.3           5.7          2.8              1
 57 Iris-versicolor           4.7          1.6           6.3          3.3              1
 58 Iris-versicolor           3.3          1.0           4.9          2.4              1
 59 Iris-versicolor           4.6          1.3           6.6          2.9              1
 60 Iris-versicolor           3.9          1.4           5.2          2.7              1
 61 Iris-versicolor           3.5          1.0           5.0          2.0              1
 62 Iris-versicolor           4.2          1.5           5.9          3.0              1
 63 Iris-versicolor           4.0          1.0           6.0          2.2              1
 64 Iris-versicolor           4.7          1.4           6.1          2.9              1
 65 Iris-versicolor           3.6          1.3           5.6          2.9              1
 66 Iris-versicolor           4.4          1.4           6.7          3.1              1
 67 Iris-versicolor           4.5          1.5           5.6          3.0              1
 68 Iris-versicolor           4.1          1.0           5.8          2.7              1
 69 Iris-versicolor           4.5          1.5           6.2          2.2              1
 70 Iris-versicolor           3.9          1.1           5.6          2.5              1
 71 Iris-versicolor           4.8          1.8           5.9          3.2              1
 72 Iris-versicolor           4.0          1.3           6.1          2.8              1
 73 Iris-versicolor           4.9          1.5           6.3          2.5              1
 74 Iris-versicolor           4.7          1.2           6.1          2.8              1
 75 Iris-versicolor           4.3          1.3           6.4          2.9              1
 76 Iris-versicolor           4.4          1.4           6.6          3.0              1
 77 Iris-versicolor           4.8          1.4           6.8          2.8              1
 78 Iris-versicolor           5.0          1.7           6.7          3.0              1
 79 Iris-versicolor           4.5          1.5           6.0          2.9              1
 80 Iris-versicolor           3.5          1.0           5.7          2.6              1
 81 Iris-versicolor           3.8          1.1           5.5          2.4              1
 82 Iris-versicolor           3.7          1.0           5.5          2.4              1
 83 Iris-versicolor           3.9          1.2           5.8          2.7              1
 84 Iris-versicolor           5.1          1.6           6.0          2.7              1
 85 Iris-versicolor           4.5          1.5           5.4          3.0              1
 86 Iris-versicolor           4.5          1.6           6.0          3.4              1
 87 Iris-versicolor           4.7          1.5           6.7          3.1              1
 88 Iris-versicolor           4.4          1.3           6.3          2.3              1
 89 Iris-versicolor           4.1          1.3           5.6          3.0              1
 90 Iris-versicolor           4.0          1.3           5.5          2.5              1
 91 Iris-versicolor           4.4          1.2           5.5          2.6              1
 92 Iris-versicolor           4.6          1.4           6.1          3.0              1
 93 Iris-versicolor           4.0          1.2           5.8          2.6              1
 94 Iris-versicolor           3.3          1.0           5.0          2.3              1
 95 Iris-versicolor           4.2          1.3           5.6          2.7              1
 96 Iris-versicolor           4.2          1.2           5.7          3.0              1
 97 Iris-versicolor           4.2          1.3           5.7          2.9              1
 98 Iris-versicolor           4.3          1.3           6.2          2.9              1
 99 Iris-versicolor           3.0          1.1           5.1          2.5              1
100 Iris-versicolor           4.1          1.3           5.7          2.8              1
101  Iris-virginica          60.0         25.0          63.0         33.0             -1
102  Iris-virginica          51.0         19.0          58.0         27.0             -1
103  Iris-virginica          59.0         21.0          71.0         30.0             -1
104  Iris-virginica          56.0         18.0          63.0         29.0             -1
105  Iris-virginica          58.0         22.0          65.0         30.0             -1
106  Iris-virginica           6.6          2.1           7.6          3.0              1
107  Iris-virginica           4.5          1.7           4.9          2.5              1
108  Iris-virginica           6.3          1.8           7.3          2.9              1
109  Iris-virginica           5.8          1.8           6.7          2.5              1
110  Iris-virginica           6.1          2.5           7.2          3.6              1
111  Iris-virginica           5.1          2.0           6.5          3.2              1
112  Iris-virginica           5.3          1.9           6.4          2.7              1
113  Iris-virginica           5.5          2.1           6.8          3.0              1
114  Iris-virginica           5.0          2.0           5.7          2.5              1
115  Iris-virginica           5.1         42.0           5.8          2.8             -1
116  Iris-virginica           5.3          2.3           6.4          3.2              1
117  Iris-virginica           5.5          1.8           6.5          3.0              1
118  Iris-virginica           6.7          2.2           7.7          3.8              1
119  Iris-virginica           6.9          2.3           7.7          2.6              1
120  Iris-virginica          50.0          1.5           6.0          2.2             -1
121  Iris-virginica           5.7          2.3           6.9          3.2              1
122  Iris-virginica           4.9          2.0           5.6          2.8              1
123  Iris-virginica           6.7          2.0           7.7          2.8              1
124  Iris-virginica           4.9          1.8           6.3          2.7              1
125  Iris-virginica           5.7          2.1           6.7          3.3              1
126  Iris-virginica           6.0         18.0           7.2          3.2             -1
127  Iris-virginica           4.8          1.8           6.2          2.8              1
128  Iris-virginica           4.9          1.8           6.1          3.0              1
129  Iris-virginica           5.6          2.1           6.4          2.8              1
130  Iris-virginica          58.0          1.6           7.2          3.0             -1
131  Iris-virginica           6.1          1.9           7.4          2.8              1
132  Iris-virginica           6.4          2.0           7.9          3.8              1
133  Iris-virginica           5.6          2.2           6.4          2.8              1
134  Iris-virginica           5.1          1.5           6.3          2.8              1
135  Iris-virginica           5.6         41.0           6.1          2.6             -1
136  Iris-virginica           6.1          2.3           7.7          3.0              1
137  Iris-virginica           5.6          2.4           6.3          3.4              1
138  Iris-virginica           5.5          1.8           6.4          3.1              1
139  Iris-virginica           4.8          1.8           6.0          3.0              1
140  Iris-virginica          45.0          2.1           6.9          3.1             -1
141  Iris-virginica           5.6          2.4           6.7          3.1              1
142  Iris-virginica           5.1          2.3           6.9          3.1              1
143  Iris-virginica           5.1          1.9           5.8          2.7              1
144  Iris-virginica           5.9          2.3           6.8          3.2              1
145  Iris-virginica           5.7         25.0           6.7          3.3             -1
146  Iris-virginica           5.2          2.3           6.7          3.0              1
147  Iris-virginica           5.0          1.9           6.3          2.5              1
148  Iris-virginica           5.2          2.0           6.5          3.0              1
149  Iris-virginica           5.4          2.3           6.2          3.4              1
150  Iris-virginica           5.1          1.8           5.9          3.0              1

Jumlah outlier: 28

Data Outlier:
 id           class  petal_length  petal_width  sepal_length  sepal_width
  1     Iris-setosa          14.0          2.0          51.0         35.0
  2     Iris-setosa          14.0          2.0          49.0         30.0
  3     Iris-setosa          13.0          2.0          47.0         32.0
  4     Iris-setosa          15.0          2.0          46.0         31.0
  5     Iris-setosa          14.0          2.0           5.0         36.0
 10     Iris-setosa           1.5          0.1          94.0          3.1
 15     Iris-setosa           1.2          0.2           5.8         40.0
 20     Iris-setosa           1.5          0.3          51.0          3.8
 25     Iris-setosa           1.9          0.2           4.8         34.0
 30     Iris-setosa           1.6          0.2          74.0          3.2
 35     Iris-setosa           1.5          0.1           4.9         94.0
 51 Iris-versicolor          47.0         14.0          70.0         32.0
 52 Iris-versicolor          45.0         15.0          64.0         32.0
 53 Iris-versicolor          49.0         15.0          69.0         31.0
 54 Iris-versicolor          40.0         13.0          55.0         23.0
 55 Iris-versicolor          46.0         15.0          65.0         28.0
101  Iris-virginica          60.0         25.0          63.0         33.0
102  Iris-virginica          51.0         19.0          58.0         27.0
103  Iris-virginica          59.0         21.0          71.0         30.0
104  Iris-virginica          56.0         18.0          63.0         29.0
105  Iris-virginica          58.0         22.0          65.0         30.0
115  Iris-virginica           5.1         42.0           5.8          2.8
120  Iris-virginica          50.0          1.5           6.0          2.2
126  Iris-virginica           6.0         18.0           7.2          3.2
130  Iris-virginica          58.0          1.6           7.2          3.0
135  Iris-virginica           5.6         41.0           6.1          2.6
140  Iris-virginica          45.0          2.1           6.9          3.1
145  Iris-virginica           5.7         25.0           6.7          3.3

Jumlah data setelah dihapus :  122

Data tidak outlier :
 id           class  petal_length  petal_width  sepal_length  sepal_width
  6     Iris-setosa           1.7          0.4           5.4          3.9
  7     Iris-setosa           1.4          0.3           4.6          3.4
  8     Iris-setosa           1.5          0.2           5.0          3.4
  9     Iris-setosa           1.4          0.2           4.4          2.9
 11     Iris-setosa           1.5          0.2           5.4          3.7
 12     Iris-setosa           1.6          0.2           4.8          3.4
 13     Iris-setosa           1.4          0.1           4.8          3.0
 14     Iris-setosa           1.1          0.1           4.3          3.0
 16     Iris-setosa           1.5          0.4           5.7          4.4
 17     Iris-setosa           1.3          0.4           5.4          3.9
 18     Iris-setosa           1.4          0.3           5.1          3.5
 19     Iris-setosa           1.7          0.3           5.7          3.8
 21     Iris-setosa           1.7          0.2           5.4          3.4
 22     Iris-setosa           1.5          0.4           5.1          3.7
 23     Iris-setosa           1.0          0.2           4.6          3.6
 24     Iris-setosa           1.7          0.5           5.1          3.3
 26     Iris-setosa           1.6          0.2           5.0          3.0
 27     Iris-setosa           1.6          0.4           5.0          3.4
 28     Iris-setosa           1.5          0.2           5.2          3.5
 29     Iris-setosa           1.4          0.2           5.2          3.4
 31     Iris-setosa           1.6          0.2           4.8          3.1
 32     Iris-setosa           1.5          0.4           5.4          3.4
 33     Iris-setosa           1.5          0.1           5.2          4.1
 34     Iris-setosa           1.4          0.2           5.5          4.2
 36     Iris-setosa           1.2          0.2           5.0          3.2
 37     Iris-setosa           1.3          0.2           5.5          3.5
 38     Iris-setosa           1.5          0.1           4.9          3.1
 39     Iris-setosa           1.3          0.2           4.4          3.0
 40     Iris-setosa           1.5          0.2           5.1          3.4
 41     Iris-setosa           1.3          0.3           5.0          3.5
 42     Iris-setosa           1.3          0.3           4.5          2.3
 43     Iris-setosa           1.3          0.2           4.4          3.2
 44     Iris-setosa           1.6          0.6           5.0          3.5
 45     Iris-setosa           1.9          0.4           5.1          3.8
 46     Iris-setosa           1.4          0.3           4.8          3.0
 47     Iris-setosa           1.6          0.2           5.1          3.8
 48     Iris-setosa           1.4          0.2           4.6          3.2
 49     Iris-setosa           1.5          0.2           5.3          3.7
 50     Iris-setosa           1.4          0.2           5.0          3.3
 56 Iris-versicolor           4.5          1.3           5.7          2.8
 57 Iris-versicolor           4.7          1.6           6.3          3.3
 58 Iris-versicolor           3.3          1.0           4.9          2.4
 59 Iris-versicolor           4.6          1.3           6.6          2.9
 60 Iris-versicolor           3.9          1.4           5.2          2.7
 61 Iris-versicolor           3.5          1.0           5.0          2.0
 62 Iris-versicolor           4.2          1.5           5.9          3.0
 63 Iris-versicolor           4.0          1.0           6.0          2.2
 64 Iris-versicolor           4.7          1.4           6.1          2.9
 65 Iris-versicolor           3.6          1.3           5.6          2.9
 66 Iris-versicolor           4.4          1.4           6.7          3.1
 67 Iris-versicolor           4.5          1.5           5.6          3.0
 68 Iris-versicolor           4.1          1.0           5.8          2.7
 69 Iris-versicolor           4.5          1.5           6.2          2.2
 70 Iris-versicolor           3.9          1.1           5.6          2.5
 71 Iris-versicolor           4.8          1.8           5.9          3.2
 72 Iris-versicolor           4.0          1.3           6.1          2.8
 73 Iris-versicolor           4.9          1.5           6.3          2.5
 74 Iris-versicolor           4.7          1.2           6.1          2.8
 75 Iris-versicolor           4.3          1.3           6.4          2.9
 76 Iris-versicolor           4.4          1.4           6.6          3.0
 77 Iris-versicolor           4.8          1.4           6.8          2.8
 78 Iris-versicolor           5.0          1.7           6.7          3.0
 79 Iris-versicolor           4.5          1.5           6.0          2.9
 80 Iris-versicolor           3.5          1.0           5.7          2.6
 81 Iris-versicolor           3.8          1.1           5.5          2.4
 82 Iris-versicolor           3.7          1.0           5.5          2.4
 83 Iris-versicolor           3.9          1.2           5.8          2.7
 84 Iris-versicolor           5.1          1.6           6.0          2.7
 85 Iris-versicolor           4.5          1.5           5.4          3.0
 86 Iris-versicolor           4.5          1.6           6.0          3.4
 87 Iris-versicolor           4.7          1.5           6.7          3.1
 88 Iris-versicolor           4.4          1.3           6.3          2.3
 89 Iris-versicolor           4.1          1.3           5.6          3.0
 90 Iris-versicolor           4.0          1.3           5.5          2.5
 91 Iris-versicolor           4.4          1.2           5.5          2.6
 92 Iris-versicolor           4.6          1.4           6.1          3.0
 93 Iris-versicolor           4.0          1.2           5.8          2.6
 94 Iris-versicolor           3.3          1.0           5.0          2.3
 95 Iris-versicolor           4.2          1.3           5.6          2.7
 96 Iris-versicolor           4.2          1.2           5.7          3.0
 97 Iris-versicolor           4.2          1.3           5.7          2.9
 98 Iris-versicolor           4.3          1.3           6.2          2.9
 99 Iris-versicolor           3.0          1.1           5.1          2.5
100 Iris-versicolor           4.1          1.3           5.7          2.8
106  Iris-virginica           6.6          2.1           7.6          3.0
107  Iris-virginica           4.5          1.7           4.9          2.5
108  Iris-virginica           6.3          1.8           7.3          2.9
109  Iris-virginica           5.8          1.8           6.7          2.5
110  Iris-virginica           6.1          2.5           7.2          3.6
111  Iris-virginica           5.1          2.0           6.5          3.2
112  Iris-virginica           5.3          1.9           6.4          2.7
113  Iris-virginica           5.5          2.1           6.8          3.0
114  Iris-virginica           5.0          2.0           5.7          2.5
116  Iris-virginica           5.3          2.3           6.4          3.2
117  Iris-virginica           5.5          1.8           6.5          3.0
118  Iris-virginica           6.7          2.2           7.7          3.8
119  Iris-virginica           6.9          2.3           7.7          2.6
121  Iris-virginica           5.7          2.3           6.9          3.2
122  Iris-virginica           4.9          2.0           5.6          2.8
123  Iris-virginica           6.7          2.0           7.7          2.8
124  Iris-virginica           4.9          1.8           6.3          2.7
125  Iris-virginica           5.7          2.1           6.7          3.3
127  Iris-virginica           4.8          1.8           6.2          2.8
128  Iris-virginica           4.9          1.8           6.1          3.0
129  Iris-virginica           5.6          2.1           6.4          2.8
131  Iris-virginica           6.1          1.9           7.4          2.8
132  Iris-virginica           6.4          2.0           7.9          3.8
133  Iris-virginica           5.6          2.2           6.4          2.8
134  Iris-virginica           5.1          1.5           6.3          2.8
136  Iris-virginica           6.1          2.3           7.7          3.0
137  Iris-virginica           5.6          2.4           6.3          3.4
138  Iris-virginica           5.5          1.8           6.4          3.1
139  Iris-virginica           4.8          1.8           6.0          3.0
141  Iris-virginica           5.6          2.4           6.7          3.1
142  Iris-virginica           5.1          2.3           6.9          3.1
143  Iris-virginica           5.1          1.9           5.8          2.7
144  Iris-virginica           5.9          2.3           6.8          3.2
146  Iris-virginica           5.2          2.3           6.7          3.0
147  Iris-virginica           5.0          1.9           6.3          2.5
148  Iris-virginica           5.2          2.0           6.5          3.0
149  Iris-virginica           5.4          2.3           6.2          3.4
150  Iris-virginica           5.1          1.8           5.9          3.0
</pre></div>
</div>
</div>
</div>
<p>Kode ini mengambil data dari PostgreSQL dan MySQL, lalu menggabungkannya berdasarkan kolom <strong>“id”</strong> dan <strong>“class”</strong>. Setelah itu, digunakan algoritma <strong>Local Outlier Factor (LOF)</strong> dengan <strong>90 tetangga terdekat</strong> untuk mendeteksi outlier berdasarkan fitur numerik <strong>(petal_length, petal_width, sepal_length, sepal_width)</strong>. Data yang memiliki label <strong>-1</strong> dianggap sebagai outlier, sementara data dengan label <strong>1</strong> dianggap normal. Hasilnya ditampilkan dalam dua kelompok: <strong>data outlier</strong> dan <strong>data yang tidak outlier</strong>, beserta jumlahnya setelah outlier dihapus.</p>
</section>
<section id="menghitung-akurasi">
<h3>Menghitung Akurasi<a class="headerlink" href="#menghitung-akurasi" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Menerapkan LOF untuk deteksi outlier</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">outlier_labels</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_labels</span>

<span class="c1"># Pisahkan data dengan outlier dan tanpa outlier</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">])</span>

<span class="c1"># Membagi data menjadi training (80%) dan testing (20%)</span>
<span class="n">X_train_all</span><span class="p">,</span> <span class="n">X_test_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">,</span> <span class="n">y_test_all</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_encoded</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">X_train_clean</span><span class="p">,</span> <span class="n">X_test_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">,</span> <span class="n">y_test_clean</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">],</span>
    <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]),</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Pipeline dengan StandardScaler dan KNN</span>
<span class="n">knn_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Latih model pada data dengan outlier</span>
<span class="n">knn_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">)</span>
<span class="n">y_pred_all</span> <span class="o">=</span> <span class="n">knn_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_all</span><span class="p">)</span>
<span class="n">accuracy_all</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi dengan outlier:&quot;</span><span class="p">,</span> <span class="n">accuracy_all</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>

<span class="c1"># Latih model pada data tanpa outlier</span>
<span class="n">knn_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">)</span>
<span class="n">y_pred_clean</span> <span class="o">=</span> <span class="n">knn_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_clean</span><span class="p">)</span>
<span class="n">accuracy_clean</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi tanpa outlier:&quot;</span><span class="p">,</span> <span class="n">accuracy_clean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi dengan outlier: 0.8666666666666667
                 precision    recall  f1-score   support

    Iris-setosa       1.00      0.70      0.82        10
Iris-versicolor       0.82      1.00      0.90         9
 Iris-virginica       0.83      0.91      0.87        11

       accuracy                           0.87        30
      macro avg       0.88      0.87      0.86        30
   weighted avg       0.88      0.87      0.86        30

Akurasi tanpa outlier: 1.0
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        13
Iris-versicolor       1.00      1.00      1.00         6
 Iris-virginica       1.00      1.00      1.00         8

       accuracy                           1.00        27
      macro avg       1.00      1.00      1.00        27
   weighted avg       1.00      1.00      1.00        27
</pre></div>
</div>
</div>
</div>
<p>Kode ini melakukan <strong>deteksi outlier</strong> menggunakan <strong>Local Outlier Factor (LOF)</strong> dan mengevaluasi dampaknya terhadap <strong>akurasi model K-Nearest Neighbors (KNN)</strong> dalam klasifikasi data <strong>Iris</strong>. Pertama, fitur numerik <strong>(X)</strong> dan label kelas <strong>(y)</strong> diekstrak dari data, lalu label kelas dikonversi ke bentuk numerik dengan <strong>LabelEncoder</strong>. LOF diterapkan untuk mengidentifikasi <strong>outlier</strong>, di mana data dengan label <strong>-1</strong> dianggap sebagai outlier dan dihapus, sehingga terbentuk <strong>df_cleaned</strong> (data tanpa outlier). Data kemudian dibagi menjadi <strong>80% training dan 20% testing</strong>, baik untuk data asli (dengan outlier) maupun data yang telah dibersihkan dari outlier. Model <strong>KNN dengan k=11</strong> diterapkan menggunakan <strong>pipeline yang mencakup StandardScaler</strong>, lalu dilatih dan dievaluasi pada kedua versi data. Hasil evaluasi menunjukkan perbandingan <strong>akurasi sebelum dan sesudah menghapus outlier</strong>, dengan <strong>classification_report</strong> yang memberikan metrik klasifikasi seperti precision, recall, dan f1-score.</p>
</section>
<section id="visualisasi">
<h3>Visualisasi<a class="headerlink" href="#visualisasi" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">DecisionBoundaryDisplay</span>

<span class="c1"># Ambil dua fitur utama untuk visualisasi decision boundary</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal_width&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Ubah nama kelas jadi angka</span>

<span class="c1"># Membagi data menjadi training (80%) dan testing (20%)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_encoded</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Pipeline dengan KNN dan StandardScaler</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Pelatihan model KNN</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluasi model</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>

<span class="c1"># Visualisasi Decision Boundary</span>
<span class="n">_</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">weights</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="s2">&quot;distance&quot;</span><span class="p">)):</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">knn__weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">disp</span> <span class="o">=</span> <span class="n">DecisionBoundaryDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
        <span class="n">clf</span><span class="p">,</span>
        <span class="n">X_test</span><span class="p">,</span>
        <span class="n">response_method</span><span class="o">=</span><span class="s2">&quot;predict&quot;</span><span class="p">,</span>
        <span class="n">plot_method</span><span class="o">=</span><span class="s2">&quot;pcolormesh&quot;</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">shading</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">scatter</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span>
    <span class="p">)</span>
    <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
        <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower left&quot;</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Classes&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;3-Class classification</span><span class="se">\n</span><span class="s2">(k=</span><span class="si">{</span><span class="n">clf</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">, weights=</span><span class="si">{</span><span class="n">weights</span><span class="si">!r}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi: 1.0
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        13
Iris-versicolor       1.00      1.00      1.00         6
 Iris-virginica       1.00      1.00      1.00         8

       accuracy                           1.00        27
      macro avg       1.00      1.00      1.00        27
   weighted avg       1.00      1.00      1.00        27
</pre></div>
</div>
<img alt="_images/bfc8cab30fd45e3ea376dc2ee616ce39cd162b567e9c757474310470c79a2b32.png" src="_images/bfc8cab30fd45e3ea376dc2ee616ce39cd162b567e9c757474310470c79a2b32.png" />
</div>
</div>
<p>Kode ini melakukan klasifikasi menggunakan algoritma K-Nearest Neighbors (KNN) dengan dua fitur utama (petal_length dan petal_width) dari dataset yang sudah dibersihkan dari outlier. Data terlebih dahulu diencode menggunakan LabelEncoder, lalu dibagi menjadi 80% training dan 20% testing. Model KNN diterapkan dalam pipeline bersama StandardScaler untuk menstandarisasi data, kemudian dilatih dengan 11 tetangga terdekat (n_neighbors=11). Evaluasi model dilakukan dengan akurasi dan classification report. Terakhir, kode membuat visualisasi decision boundary dari model KNN dengan dua skenario pembobotan (uniform dan distance), menggunakan DecisionBoundaryDisplay untuk menggambarkan bagaimana model membedakan kelas berdasarkan fitur yang dipilih.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">pymysql</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">DecisionBoundaryDisplay</span>


<span class="c1"># Ambil dua fitur utama untuk visualisasi decision boundary</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sepal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_width&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Mengubah nama kelas menjadi angka</span>

<span class="c1"># Menerapkan LOF untuk deteksi outlier</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">outlier_labels</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_labels</span>

<span class="c1"># Menghapus data yang terdeteksi sebagai outlier</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">])</span>

<span class="c1"># Membagi data menjadi training (80%) dan testing (20%)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">],</span>
    <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]),</span>  <span class="c1"># Pastikan target dalam bentuk numerik</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Pipeline dengan KNN dan StandardScaler</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Pelatihan model KNN</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluasi model</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>

<span class="c1"># Visualisasi Decision Boundary</span>
<span class="n">_</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">weights</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="s2">&quot;distance&quot;</span><span class="p">)):</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">knn__weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">disp</span> <span class="o">=</span> <span class="n">DecisionBoundaryDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
        <span class="n">clf</span><span class="p">,</span>
        <span class="n">X_test</span><span class="p">,</span>
        <span class="n">response_method</span><span class="o">=</span><span class="s2">&quot;predict&quot;</span><span class="p">,</span>
        <span class="n">plot_method</span><span class="o">=</span><span class="s2">&quot;pcolormesh&quot;</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">shading</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">scatter</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span>
    <span class="p">)</span>
    <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
        <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower left&quot;</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Classes&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;3-Class classification</span><span class="se">\n</span><span class="s2">(k=</span><span class="si">{</span><span class="n">clf</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">, weights=</span><span class="si">{</span><span class="n">weights</span><span class="si">!r}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi: 0.7037037037037037
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00         9
Iris-versicolor       0.62      0.50      0.56        10
 Iris-virginica       0.50      0.62      0.56         8

       accuracy                           0.70        27
      macro avg       0.71      0.71      0.70        27
   weighted avg       0.71      0.70      0.70        27
</pre></div>
</div>
<img alt="_images/f0238c111f098a54fc23f97ebe398594ecdd3bc2c25490168d9890c6ef72e217.png" src="_images/f0238c111f098a54fc23f97ebe398594ecdd3bc2c25490168d9890c6ef72e217.png" />
</div>
</div>
<p>Kode ini melakukan deteksi outlier dengan LOF dan klasifikasi dengan KNN menggunakan fitur sepal_length dan sepal_width. Pertama, data dikodekan menggunakan LabelEncoder, lalu outlier diidentifikasi dengan Local Outlier Factor (LOF) menggunakan 20 tetangga (n_neighbors=20) dan 10% data dianggap outlier (contamination=0.1). Data yang terdeteksi sebagai outlier dihapus sebelum digunakan dalam pembagian data training (80%) dan testing (20%). Model KNN dengan 11 tetangga (n_neighbors=11) diterapkan dalam pipeline bersama StandardScaler, lalu dilatih dan dievaluasi menggunakan akurasi dan classification report. Terakhir, kode membuat visualisasi decision boundary dengan dua skenario bobot (uniform dan distance), menunjukkan bagaimana model memisahkan kelas berdasarkan fitur yang dipilih.</p>
</section>
</section>
<section id="klasifikasi-dengan-naive-baiyes">
<h2>Klasifikasi  Dengan Naive Baiyes<a class="headerlink" href="#klasifikasi-dengan-naive-baiyes" title="Link to this heading">#</a></h2>
<section id="menyiapkan-data">
<h3>Menyiapkan Data<a class="headerlink" href="#menyiapkan-data" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class_encoded&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">])</span>

<span class="c1"># Data dengan outlier</span>
<span class="n">X_all</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y_all</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class_encoded&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Pastikan dalam bentuk array numpy</span>

<span class="c1"># Data tanpa outlier</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">])</span>
<span class="n">X_clean</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y_clean</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class_encoded&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Pastikan dalam bentuk array numpy</span>
</pre></div>
</div>
</div>
</div>
<p>Kode ini mengonversi label kelas menjadi numerik menggunakan LabelEncoder() agar dapat digunakan dalam model machine learning. Setelah itu, dataset dibagi menjadi dua bagian: satu dengan outlier dan satu tanpa outlier. Dataset dengan outlier disimpan dalam X_all untuk fitur dan y_all untuk label kelas yang telah dikonversi. Sementara itu, dataset tanpa outlier difilter dengan hanya menyertakan baris di mana outlier == 1, lalu kolom outlier dihapus. Data hasil pembersihan ini disimpan dalam X_clean untuk fitur dan y_clean untuk label kelas dalam bentuk numerik, memastikan bahwa analisis dapat dilakukan baik dengan maupun tanpa outlier.</p>
</section>
<section id="pelatihan-pengujian-dan-evaluasi-model-naive-bayes">
<h3>Pelatihan, Pengujian, dan Evaluasi Model Naïve Bayes<a class="headerlink" href="#pelatihan-pengujian-dan-evaluasi-model-naive-bayes" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Split data dengan outlier</span>
<span class="n">X_train_all</span><span class="p">,</span> <span class="n">X_test_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">,</span> <span class="n">y_test_all</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_all</span><span class="p">,</span> <span class="n">y_all</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Split data tanpa outlier</span>
<span class="n">X_train_clean</span><span class="p">,</span> <span class="n">X_test_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">,</span> <span class="n">y_test_clean</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_clean</span><span class="p">,</span> <span class="n">y_clean</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Inisialisasi model Naive Bayes</span>
<span class="n">gnb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1"># Latih dan uji model dengan outlier</span>
<span class="n">y_pred_all</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_all</span><span class="p">)</span>
<span class="n">accuracy_all</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">)</span>

<span class="c1"># Latih dan uji model tanpa outlier</span>
<span class="n">y_pred_clean</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_clean</span><span class="p">)</span>
<span class="n">accuracy_clean</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">)</span>

<span class="c1"># Evaluasi model dengan outlier</span>
<span class="n">mislabeled_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_test_all</span> <span class="o">!=</span> <span class="n">y_pred_all</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah data yang salah diklasifikasikan dengan outlier dari total </span><span class="si">%d</span><span class="s2"> data : </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test_all</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mislabeled_all</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi dengan outlier: </span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy_all</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>

<span class="c1"># Menampilkan label yang salah pada data dengan outlier</span>
<span class="n">mislabeled_indices_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test_all</span> <span class="o">!=</span> <span class="n">y_pred_all</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data yang salah diklasifikasikan dengan outlier:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">mislabeled_indices_all</span><span class="p">:</span>
    <span class="n">true_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_pred_all</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Indeks: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, Label Asli: </span><span class="si">{</span><span class="n">true_label</span><span class="si">}</span><span class="s2">, Prediksi: </span><span class="si">{</span><span class="n">predicted_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Evaluasi model tanpa outlier</span>
<span class="n">mislabeled_clean</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_test_clean</span> <span class="o">!=</span> <span class="n">y_pred_clean</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah data yang salah diklasifikasikan tanpa outlier dari total </span><span class="si">%d</span><span class="s2"> data : </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test_clean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mislabeled_clean</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi tanpa outlier: </span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy_clean</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>

<span class="c1"># Menampilkan label yang salah pada data tanpa outlier</span>
<span class="n">mislabeled_indices_clean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test_clean</span> <span class="o">!=</span> <span class="n">y_pred_clean</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data yang salah diklasifikasikan tanpa outlier:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">mislabeled_indices_clean</span><span class="p">:</span>
    <span class="n">true_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_pred_clean</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Indeks: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, Label Asli: </span><span class="si">{</span><span class="n">true_label</span><span class="si">}</span><span class="s2">, Prediksi: </span><span class="si">{</span><span class="n">predicted_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah data yang salah diklasifikasikan dengan outlier dari total 30 data : 20
Akurasi dengan outlier: 33.33%
Data yang salah diklasifikasikan dengan outlier:
Indeks: 0, Label Asli: Iris-versicolor, Prediksi: Iris-virginica
Indeks: 1, Label Asli: Iris-setosa, Prediksi: Iris-virginica
Indeks: 3, Label Asli: Iris-versicolor, Prediksi: Iris-virginica
Indeks: 4, Label Asli: Iris-versicolor, Prediksi: Iris-virginica
Indeks: 5, Label Asli: Iris-setosa, Prediksi: Iris-virginica
Indeks: 6, Label Asli: Iris-versicolor, Prediksi: Iris-virginica
Indeks: 8, Label Asli: Iris-versicolor, Prediksi: Iris-virginica
Indeks: 9, Label Asli: Iris-versicolor, Prediksi: Iris-virginica
Indeks: 11, Label Asli: Iris-setosa, Prediksi: Iris-virginica
Indeks: 12, Label Asli: Iris-setosa, Prediksi: Iris-virginica
Indeks: 13, Label Asli: Iris-setosa, Prediksi: Iris-versicolor
Indeks: 14, Label Asli: Iris-setosa, Prediksi: Iris-versicolor
Indeks: 15, Label Asli: Iris-versicolor, Prediksi: Iris-virginica
Indeks: 16, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 17, Label Asli: Iris-versicolor, Prediksi: Iris-virginica
Indeks: 18, Label Asli: Iris-versicolor, Prediksi: Iris-virginica
Indeks: 20, Label Asli: Iris-setosa, Prediksi: Iris-versicolor
Indeks: 22, Label Asli: Iris-setosa, Prediksi: Iris-virginica
Indeks: 28, Label Asli: Iris-setosa, Prediksi: Iris-virginica
Indeks: 29, Label Asli: Iris-setosa, Prediksi: Iris-virginica

Jumlah data yang salah diklasifikasikan tanpa outlier dari total 27 data : 14
Akurasi tanpa outlier: 48.15%
Data yang salah diklasifikasikan tanpa outlier:
Indeks: 0, Label Asli: Iris-virginica, Prediksi: Iris-setosa
Indeks: 1, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 2, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 7, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 8, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 9, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 11, Label Asli: Iris-versicolor, Prediksi: Iris-virginica
Indeks: 13, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 14, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 18, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 19, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 20, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 25, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 26, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
</pre></div>
</div>
</div>
</div>
<p>Kode ini melakukan evaluasi model Naïve Bayes pada dataset dengan dan tanpa outlier untuk membandingkan akurasi klasifikasinya. Pertama, dataset dibagi menjadi data latih dan data uji menggunakan train_test_split, baik untuk data yang mengandung outlier maupun yang telah dibersihkan dari outlier. Model Naïve Bayes (GaussianNB) kemudian dilatih dan diuji pada kedua versi dataset, dengan hasil prediksi dibandingkan dengan label sebenarnya menggunakan metrik accuracy_score. Jumlah data yang salah diklasifikasikan dihitung dan ditampilkan untuk kedua skenario, serta akurasinya dalam persentase. Selain itu, kode juga mengidentifikasi dan mencetak indeks serta label dari data yang diklasifikasikan secara salah dalam kedua kondisi, dengan menerjemahkan label numerik kembali ke bentuk aslinya menggunakan LabelEncoder. Tujuan dari proses ini adalah untuk memahami dampak keberadaan outlier terhadap performa model, di mana hasil akhirnya menunjukkan perbandingan akurasi dan jumlah kesalahan klasifikasi dengan dan tanpa outlier.</p>
</section>
<section id="visualisasi-confussion-matrix">
<h3>Visualisasi Confussion Matrix<a class="headerlink" href="#visualisasi-confussion-matrix" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Confusion Matrix dengan outlier</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix with Outliers&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>

<span class="c1"># Confusion Matrix tanpa outlier</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix without Outliers&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fa867386e54db8fda6452ee045f9cd1ab6a3bc495ee248bf6ae64d6e983f4420.png" src="_images/fa867386e54db8fda6452ee045f9cd1ab6a3bc495ee248bf6ae64d6e983f4420.png" />
</div>
</div>
<p>Kode ini bertujuan untuk memvisualisasikan performa model Naïve Bayes menggunakan confusion matrix dalam dua kondisi: dengan dan tanpa outlier. Menggunakan matplotlib dan seaborn, dua confusion matrix dibuat dalam satu figure dengan dua subplot yang bersebelahan. Masing-masing confusion matrix menggambarkan perbandingan antara label sebenarnya (y_test_all atau y_test_clean) dengan hasil prediksi model (y_pred_all atau y_pred_clean). Warna biru digunakan untuk memperjelas jumlah prediksi dalam tiap kategori, dan nilai prediksi ditampilkan dalam setiap sel menggunakan annot=True. Sumbu horizontal merepresentasikan label yang diprediksi, sementara sumbu vertikal menunjukkan label sebenarnya. Dengan visualisasi ini, kita dapat melihat pola kesalahan klasifikasi dan membandingkan bagaimana keberadaan outlier mempengaruhi kinerja model.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="pendat1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Data UnderStanding</p>
      </div>
    </a>
    <a class="right-next"
       href="uts.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">UTS PENDAT</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-outlier">Deteksi Outlier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tahap-deteksi-outlier-dengan-knn">Tahap Deteksi Outlier dengan KNN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">Kesimpulan</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-outlier-factor-lof">Local Outlier Factor (LOF)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tahapan-lof">Tahapan LOF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengitung-manual">Mengitung Manual</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-lof-menggunakan-scikit-learn">Implementasi LOF menggunakan Scikit-Learn</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-knn">Klasifikasi Dengan KNN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memisahkan-outlier-dari-data">Memisahkan Outlier Dari Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menghitung-akurasi">Menghitung Akurasi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi">Visualisasi</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-naive-baiyes">Klasifikasi  Dengan Naive Baiyes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menyiapkan-data">Menyiapkan Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pelatihan-pengujian-dan-evaluasi-model-naive-bayes">Pelatihan, Pengujian, dan Evaluasi Model Naïve Bayes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi-confussion-matrix">Visualisasi Confussion Matrix</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Vania Putri
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>