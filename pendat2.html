
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Data Understanding (Outlier) &#8212; WebStatisku</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'pendat2';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="UTS PENDAT" href="uts.html" />
    <link rel="prev" title="Data UnderStanding" href="pendat1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="WebStatisku - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="WebStatisku - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Selamat Datang Web Statis Penambangan Data
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="pendat1.html">Data UnderStanding</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Data Understanding (Outlier)</a></li>
<li class="toctree-l1"><a class="reference internal" href="uts.html">UTS PENDAT</a></li>
<li class="toctree-l1"><a class="reference internal" href="pendat3.html"><strong>Algoritma <em>K-Means</em></strong></a></li>


<li class="toctree-l1"><a class="reference internal" href="pendat4.html"><strong>FUZZY C-MEANS</strong></a></li>

<li class="toctree-l1"><a class="reference internal" href="pendat5.html">Decision Tree</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fpendat2.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/pendat2.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Data Understanding (Outlier)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-outlier">Deteksi Outlier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tahap-deteksi-outlier-dengan-knn">Tahap Deteksi Outlier dengan KNN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">Kesimpulan</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-outlier-factor-lof">Local Outlier Factor (LOF)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tahapan-lof">Tahapan LOF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengitung-manual">Mengitung Manual</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-lof-menggunakan-scikit-learn">Implementasi LOF menggunakan Scikit-Learn</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-knn">Klasifikasi Dengan KNN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memisahkan-outlier-dari-data">Memisahkan Outlier Dari Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menghitung-akurasi">Menghitung Akurasi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi">Visualisasi</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-naive-baiyes">Klasifikasi  Dengan Naive Baiyes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menyiapkan-data">Menyiapkan Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pelatihan-pengujian-dan-evaluasi-model-naive-bayes">Pelatihan, Pengujian, dan Evaluasi Model Naïve Bayes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi-confussion-matrix">Visualisasi Confussion Matrix</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="data-understanding-outlier">
<h1>Data Understanding (Outlier)<a class="headerlink" href="#data-understanding-outlier" title="Link to this heading">#</a></h1>
<section id="deteksi-outlier">
<h2>Deteksi Outlier<a class="headerlink" href="#deteksi-outlier" title="Link to this heading">#</a></h2>
<p>Outlier adalah data yang berbeda jauh dari pola umum dalam dataset. Penyebabnya bisa karena kesalahan pengukuran, input data yang salah, atau fenomena unik. Outlier bisa memengaruhi hasil analisis dan model machine learning, sehingga perlu dideteksi.</p>
</section>
<section id="k-nearest-neighbors-knn">
<h2>K-Nearest Neighbors (KNN)<a class="headerlink" href="#k-nearest-neighbors-knn" title="Link to this heading">#</a></h2>
<p>KNN bekerja dengan melihat kedekatan antar data. Dalam deteksi outlier, KNN mengukur jarak antara suatu titik dengan tetangga terdekatnya:</p>
<ul class="simple">
<li><p>Jika suatu titik hanya memiliki sedikit tetangga dalam radius tertentu, kemungkinan besar itu outlier.</p></li>
<li><p>Jika jarak ke tetangga terdekat sangat besar, titik tersebut bisa dianggap sebagai outlier.</p></li>
</ul>
<section id="tahap-deteksi-outlier-dengan-knn">
<h3>Tahap Deteksi Outlier dengan KNN<a class="headerlink" href="#tahap-deteksi-outlier-dengan-knn" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Menghitung Jarak Antar Titik</p></li>
</ol>
<ul class="simple">
<li><p>Menggunakan metrik jarak seperti Euclidean, Manhattan, atau Minkowski untuk mengukur kedekatan antar data.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Menentukan Nilai K (Jumlah Tetangga Terdekat)</p></li>
</ol>
<ul class="simple">
<li><p>K terlalu kecil: terlalu sensitif terhadap noise.</p></li>
<li><p>K terlalu besar: kurang akurat dalam mendeteksi outlier.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Menentukan Skor Outlier</p></li>
</ol>
<ul class="simple">
<li><p>K-Nearest Neighbor Distance: Jika jarak ke K tetangga terlalu besar, kemungkinan outlier.</p></li>
<li><p>Local Outlier Factor (LOF): Membandingkan kepadatan suatu titik dengan tetangganya. Jika kepadatannya lebih rendah, kemungkinan outlier.</p></li>
<li><p>Distance-Based Outlier Score: Jika jumlah tetangga dalam radius tertentu sangat sedikit, bisa dianggap outlier.</p></li>
</ul>
</section>
<section id="kesimpulan">
<h3>Kesimpulan<a class="headerlink" href="#kesimpulan" title="Link to this heading">#</a></h3>
<p>KNN bisa digunakan untuk mendeteksi outlier dengan menganalisis jarak antara titik data dan tetangganya. Metode seperti K-Nearest Neighbor Distance dan LOF membantu mengidentifikasi data yang berbeda jauh dari pola umum. Pemilihan K dan metrik jarak yang tepat sangat penting untuk akurasi deteksi outlier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">pymysql</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>

<span class="c1"># ✅ Fungsi untuk mengambil data dari PostgreSQL</span>
<span class="k">def</span> <span class="nf">get_pg_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;pg-29vania-vaniaptr008-f94a.k.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_jN7GWD4QIOAFWBZiFM2&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">12525</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM iris_postgresql&quot;</span><span class="p">)</span>  <span class="c1"># Pastikan tabel ini ada!</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># ✅ Fungsi untuk mengambil data dari MySQL</span>
<span class="k">def</span> <span class="nf">get_mysql_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;mysql-25907135-mysqql.h.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_-_iUzbq84ojauwfvOBS&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">12005</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM iris_mysql&quot;</span><span class="p">)</span>  <span class="c1"># Pastikan tabel ini ada!</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># ✅ Ambil data dari kedua database</span>
<span class="n">df_postgresql</span> <span class="o">=</span> <span class="n">get_pg_data</span><span class="p">()</span>
<span class="n">df_mysql</span> <span class="o">=</span> <span class="n">get_mysql_data</span><span class="p">()</span>

<span class="c1"># ✅ Gabungkan berdasarkan kolom &#39;id&#39; &amp; &#39;class&#39;</span>
<span class="n">df_merged</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_mysql</span><span class="p">,</span> <span class="n">df_postgresql</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;inner&quot;</span><span class="p">)</span>

<span class="c1"># ✅ Ambil data fitur numerik</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal_width&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_width&quot;</span><span class="p">]</span>
<span class="n">data_values</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># ✅ Fungsi KNN Outlier Detection</span>
<span class="k">def</span> <span class="nf">knn_outlier_detection</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">90</span><span class="p">):</span>
    <span class="n">neigh</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">neigh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">distances</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">neigh</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">avg_distances</span> <span class="o">=</span> <span class="n">distances</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Ambil jarak k-terjauh sebagai skor</span>
    <span class="k">return</span> <span class="n">avg_distances</span>

<span class="c1"># ✅ Hitung K-NN distance</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">knn_outlier_detection</span><span class="p">(</span><span class="n">data_values</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>

<span class="c1"># ✅ Tentukan threshold sebagai nilai rata-rata + 2 standar deviasi</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier_knn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;knn_distance&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span>

<span class="c1"># ✅ Hapus data outlier</span>
<span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="o">~</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier_knn&quot;</span><span class="p">]]</span>

<span class="c1"># ✅ Cetak hasil setelah outlier dihapus</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_filtered</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah data setelah outlier dihapus: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df_filtered</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># ✅ Visualisasi setelah outlier dihapus</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;sepal_length&quot;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;sepal_width&quot;</span><span class="p">],</span>
    <span class="n">hue</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;deep&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Data Sepal setelah Outlier Dihapus&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;petal_width&quot;</span><span class="p">],</span>
    <span class="n">hue</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;deep&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Data Petal setelah Outlier Dihapus&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">OperationalError</span><span class="g g-Whitespace">                          </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">44</span>
<span class="g g-Whitespace">     </span><span class="mi">41</span>     <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">43</span> <span class="c1"># ✅ Ambil data dari kedua database</span>
<span class="ne">---&gt; </span><span class="mi">44</span> <span class="n">df_postgresql</span> <span class="o">=</span> <span class="n">get_pg_data</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">45</span> <span class="n">df_mysql</span> <span class="o">=</span> <span class="n">get_mysql_data</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">47</span> <span class="c1"># ✅ Gabungkan berdasarkan kolom &#39;id&#39; &amp; &#39;class&#39;</span>

<span class="nn">Cell In[1], line 11,</span> in <span class="ni">get_pg_data</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="k">def</span> <span class="nf">get_pg_data</span><span class="p">():</span>
<span class="ne">---&gt; </span><span class="mi">11</span>     <span class="n">conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span>         <span class="n">host</span><span class="o">=</span><span class="s2">&quot;pg-29vania-vaniaptr008-f94a.k.aivencloud.com&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span>         <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span>         <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_jN7GWD4QIOAFWBZiFM2&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span>         <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span>         <span class="n">port</span><span class="o">=</span><span class="mi">12525</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span>     <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span>     <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span>     <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM iris_postgresql&quot;</span><span class="p">)</span>  <span class="c1"># Pastikan tabel ini ada!</span>

<span class="nn">File ~\AppData\Local\Programs\Python\Python311\Lib\site-packages\psycopg2\__init__.py:122,</span> in <span class="ni">connect</span><span class="nt">(dsn, connection_factory, cursor_factory, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">119</span>     <span class="n">kwasync</span><span class="p">[</span><span class="s1">&#39;async_&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;async_&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">121</span> <span class="n">dsn</span> <span class="o">=</span> <span class="n">_ext</span><span class="o">.</span><span class="n">make_dsn</span><span class="p">(</span><span class="n">dsn</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">122</span> <span class="n">conn</span> <span class="o">=</span> <span class="n">_connect</span><span class="p">(</span><span class="n">dsn</span><span class="p">,</span> <span class="n">connection_factory</span><span class="o">=</span><span class="n">connection_factory</span><span class="p">,</span> <span class="o">**</span><span class="n">kwasync</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">123</span> <span class="k">if</span> <span class="n">cursor_factory</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">124</span>     <span class="n">conn</span><span class="o">.</span><span class="n">cursor_factory</span> <span class="o">=</span> <span class="n">cursor_factory</span>

<span class="ne">OperationalError</span>: could not translate host name &quot;pg-29vania-vaniaptr008-f94a.k.aivencloud.com&quot; to address: No such host is known. 
</pre></div>
</div>
</div>
</div>
<p>Kode ini mengambil data dari PostgreSQL dan MySQL, lalu menggabungkannya berdasarkan kolom “id” dan “class”. Setelah itu, dilakukan deteksi outlier menggunakan K-Nearest Neighbors (KNN) dengan menghitung jarak rata-rata ke 90 tetangga terdekat, kemudian data dengan jarak di atas rata-rata plus 2 standar deviasi dianggap outlier dan dihapus. Terakhir, hasil data yang telah dibersihkan divisualisasikan dalam scatter plot berdasarkan fitur sepal dan petal untuk melihat perbedaan sebelum dan sesudah penghapusan outlier.</p>
</section>
</section>
<section id="local-outlier-factor-lof">
<h2>Local Outlier Factor (LOF)<a class="headerlink" href="#local-outlier-factor-lof" title="Link to this heading">#</a></h2>
<p>Local Outlier Factor (LOF) adalah metode berbasis kepadatan yang digunakan untuk mengidentifikasi outlier dalam suatu dataset. LOF membandingkan kepadatan lokal suatu titik dengan kepadatan lokal dari tetangganya. Jika suatu titik memiliki kepadatan yang jauh lebih rendah dibandingkan dengan sekitarnya, maka titik tersebut dianggap sebagai outlier.</p>
<p>LOF mengukur sejauh mana suatu titik berbeda dari tetangganya dalam hal kepadatan. Metode ini berguna dalam mendeteksi outlier karena tidak hanya mempertimbangkan jarak absolut, tetapi juga pola kepadatan lokal. LOF memberikan skor, di mana nilai lebih tinggi menunjukkan bahwa titik tersebut lebih mungkin menjadi outlier.</p>
<section id="tahapan-lof">
<h3>Tahapan LOF<a class="headerlink" href="#tahapan-lof" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Menentukan jumlah tetangga (k-nearest neighbors, k): LOF membutuhkan parameter k yang menentukan jumlah tetangga yang akan dianalisis untuk setiap titik.</p></li>
<li><p>Menghitung jarak k-tetangga terdekat: Untuk setiap titik, dihitung jarak ke k tetangga terdekatnya.</p></li>
<li><p>Menentukan kepadatan lokal: Kepadatan lokal dihitung berdasarkan jarak rata-rata ke tetangga terdekat.</p></li>
<li><p>Menghitung LOF score: Perbandingan kepadatan lokal titik dengan kepadatan lokal dari tetangga-tetangganya digunakan untuk menentukan apakah suatu titik adalah outlier.</p></li>
<li><p>Menentukan threshold outlier: Biasanya, nilai LOF yang lebih tinggi dari ambang batas tertentu dianggap sebagai outlier.</p></li>
</ol>
</section>
<section id="mengitung-manual">
<h3>Mengitung Manual<a class="headerlink" href="#mengitung-manual" title="Link to this heading">#</a></h3>
<p>Sebagai contoh, kita akan menghitung LOF secara manual menggunakan dataset kecil yang terdiri dari 10 baris dengan 2 fitur:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>ID</p></th>
<th class="head"><p>Feature 1</p></th>
<th class="head"><p>Feature 2</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>2.0</p></td>
<td><p>3.0</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>2.5</p></td>
<td><p>3.2</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>2.2</p></td>
<td><p>3.1</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>8.0</p></td>
<td><p>9.0</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>2.1</p></td>
<td><p>3.0</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>2.3</p></td>
<td><p>3.2</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p>8.1</p></td>
<td><p>9.2</p></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p>2.4</p></td>
<td><p>3.3</p></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><p>2.6</p></td>
<td><p>3.4</p></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><p>7.9</p></td>
<td><p>9.1</p></td>
</tr>
</tbody>
</table>
</div>
<p>Misalkan kita ingin menghitung LOF untuk titik <strong>ID = 3 (2.2, 3.1)</strong>.</p>
<ol class="arabic">
<li><p><strong>Hitung Jarak Euclidean ke Tetangga Terdekat</strong>:</p>
<ul class="simple">
<li><p>Ke titik 5 (2.1, 3.0): 0.14</p></li>
<li><p>Ke titik 6 (2.3, 3.2): 0.14</p></li>
<li><p>Ke titik 2 (2.5, 3.2): 0.31</p></li>
</ul>
</li>
<li><p><strong>Tentukan k-Tetangga Terdekat (k=3)</strong>:</p>
<ul class="simple">
<li><p>Tetangga terdekat: titik 5, 6, dan 2.</p></li>
</ul>
</li>
<li><p><strong>Hitung Reachability Distance</strong>:</p>
<ul class="simple">
<li><p>Reachability distance dihitung sebagai maksimum antara jarak Euclidean dan jarak k-neighbor.</p></li>
<li><p>rD(3,5) = max(0.14, 0.31) = 0.31</p></li>
<li><p>rD(3,6) = max(0.14, 0.31) = 0.31</p></li>
<li><p>rD(3,2) = max(0.31, 0.31) = 0.31</p></li>
</ul>
</li>
<li><p><strong>Hitung Local Reachability Density (LRD)</strong>:</p>
<p><img alt="image.png" src="_images/image1.png" /></p>
</li>
<li><p><strong>Hitung LOF</strong>:</p></li>
</ol>
<p><img alt="image.png" src="_images/image2.png" /></p>
<ol class="arabic simple" start="7">
<li><p><strong>Interpretasi</strong>:</p>
<ul class="simple">
<li><p>Karena <strong>LOF &lt; 1</strong>, titik <strong>ID = 3</strong> bukan outlier.</p></li>
<li><p>Jika LOF jauh lebih besar dari 1, titik akan dianggap outlier.</p></li>
</ul>
</li>
</ol>
</section>
<section id="implementasi-lof-menggunakan-scikit-learn">
<h3>Implementasi LOF menggunakan Scikit-Learn<a class="headerlink" href="#implementasi-lof-menggunakan-scikit-learn" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Feature 1&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">8.1</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mf">2.6</span><span class="p">,</span> <span class="mf">7.9</span><span class="p">],</span>
    <span class="s2">&quot;Feature 2&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">,</span> <span class="mf">9.2</span><span class="p">,</span> <span class="mf">3.3</span><span class="p">,</span> <span class="mf">3.4</span><span class="p">,</span> <span class="mf">9.1</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Model LOF</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;LOF Label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Menampilkan jumlah outlier</span>
<span class="n">num_outliers</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;LOF Label&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah outlier: </span><span class="si">{</span><span class="n">num_outliers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menampilkan data outlier</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;LOF Label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data Outlier:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outliers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah outlier: 3

Data Outlier:
   Feature 1  Feature 2  LOF Label
3        8.0        9.0         -1
6        8.1        9.2         -1
9        7.9        9.1         -1
</pre></div>
</div>
</div>
</div>
<p>Kode di atas menggunakan metode <strong>Local Outlier Factor (LOF)</strong> dari pustaka <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> untuk mendeteksi <strong>outlier</strong> dalam dataset. Dataset terdiri dari dua fitur dengan 10 sampel yang disimpan dalam bentuk <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>. Model LOF dibuat dengan mempertimbangkan <strong>3 tetangga terdekat</strong> (<code class="docutils literal notranslate"><span class="pre">n_neighbors=3</span></code>) untuk menghitung kepadatan lokal setiap titik. Hasil perhitungan LOF mengembalikan label <code class="docutils literal notranslate"><span class="pre">1</span></code> untuk data normal dan <code class="docutils literal notranslate"><span class="pre">-1</span></code> untuk data yang dianggap <strong>outlier</strong>. Setelah itu, kode menghitung jumlah outlier dan menampilkan daftar sampel yang terdeteksi sebagai <strong>outlier</strong> berdasarkan skor LOF. Dengan pendekatan ini, kita dapat mengidentifikasi data yang berbeda secara signifikan dari sekitarnya, yang berguna dalam <strong>analisis data</strong> dan <strong>pembersihan dataset</strong>.</p>
</section>
</section>
<section id="klasifikasi-dengan-knn">
<h2>Klasifikasi Dengan KNN<a class="headerlink" href="#klasifikasi-dengan-knn" title="Link to this heading">#</a></h2>
<section id="memisahkan-outlier-dari-data">
<h3>Memisahkan Outlier Dari Data<a class="headerlink" href="#memisahkan-outlier-dari-data" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">pymysql</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>

<span class="c1"># ✅ Fungsi untuk mengambil data dari PostgreSQL</span>
<span class="k">def</span> <span class="nf">get_pg_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;pg-29vania-vaniaptr008-f94a.k.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_jN7GWD4QIOAFWBZiFM2&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">12525</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM iris_postgresql&quot;</span><span class="p">)</span>  <span class="c1"># Pastikan tabel ini ada!</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># ✅ Fungsi untuk mengambil data dari MySQL</span>
<span class="k">def</span> <span class="nf">get_mysql_data</span><span class="p">():</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">pymysql</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span>
        <span class="n">host</span><span class="o">=</span><span class="s2">&quot;mysql-25907135-mysqql.h.aivencloud.com&quot;</span><span class="p">,</span>
        <span class="n">user</span><span class="o">=</span><span class="s2">&quot;avnadmin&quot;</span><span class="p">,</span>
        <span class="n">password</span><span class="o">=</span><span class="s2">&quot;AVNS_-_iUzbq84ojauwfvOBS&quot;</span><span class="p">,</span>
        <span class="n">database</span><span class="o">=</span><span class="s2">&quot;defaultdb&quot;</span><span class="p">,</span>
        <span class="n">port</span><span class="o">=</span><span class="mi">12005</span>
    <span class="p">)</span>
    <span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM iris_mysql&quot;</span><span class="p">)</span>  <span class="c1"># Pastikan tabel ini ada!</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchall</span><span class="p">()</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">desc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">desc</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
    <span class="n">cursor</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># ✅ Ambil data dari kedua database</span>
<span class="n">df_postgresql</span> <span class="o">=</span> <span class="n">get_pg_data</span><span class="p">()</span>
<span class="n">df_mysql</span> <span class="o">=</span> <span class="n">get_mysql_data</span><span class="p">()</span>

<span class="c1"># Gabungkan berdasarkan kolom &#39;id&#39; dan &#39;class&#39;</span>
<span class="n">df_merge</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_mysql</span><span class="p">,</span> <span class="n">df_postgresql</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;class&quot;</span><span class="p">],</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;inner&quot;</span><span class="p">)</span>

<span class="c1"># Ambil data fitur numerik tanpa kolom &#39;class&#39;</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal_width&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_width&quot;</span><span class="p">]</span>
<span class="n">data_values</span> <span class="o">=</span> <span class="n">df_merge</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Inisialisasi model LOF</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">data_values</span><span class="p">)</span>

<span class="c1"># Tambahkan hasil label ke dataframe</span>
<span class="n">df_merge</span><span class="p">[</span><span class="s2">&quot;outlier_label&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">label</span>

<span class="c1"># Cetak hasil dengan ID dan class</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_merge</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="n">num_outliers</span> <span class="o">=</span> <span class="p">(</span><span class="n">label</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah outlier: </span><span class="si">{</span><span class="n">num_outliers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df_merge</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier_label&quot;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">df_merge</span><span class="p">[</span><span class="n">label</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier_label&quot;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data Outlier:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outliers</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jumlah data setelah dihapus : &quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df_filtered</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Data tidak outlier :&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_filtered</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> id           class  petal_length  petal_width  sepal_length  sepal_width  outlier_label
  1     Iris-setosa          14.0          2.0          51.0         35.0             -1
  2     Iris-setosa          14.0          2.0          49.0         30.0             -1
  3     Iris-setosa          13.0          2.0          47.0         32.0             -1
  4     Iris-setosa          15.0          2.0          46.0         31.0             -1
  5     Iris-setosa          14.0          2.0           5.0         36.0             -1
  6     Iris-setosa           1.7          0.4           5.4          3.9              1
  7     Iris-setosa           1.4          0.3           4.6          3.4              1
  8     Iris-setosa           1.5          0.2           5.0          3.4              1
  9     Iris-setosa           1.4          0.2           4.4          2.9              1
 10     Iris-setosa           1.5          0.1          94.0          3.1             -1
 11     Iris-setosa           1.5          0.2           5.4          3.7              1
 12     Iris-setosa           1.6          0.2           4.8          3.4              1
 13     Iris-setosa           1.4          0.1           4.8          3.0              1
 14     Iris-setosa           1.1          0.1           4.3          3.0              1
 15     Iris-setosa           1.2          0.2           5.8         40.0             -1
 16     Iris-setosa           1.5          0.4           5.7          4.4              1
 17     Iris-setosa           1.3          0.4           5.4          3.9              1
 18     Iris-setosa           1.4          0.3           5.1          3.5              1
 19     Iris-setosa           1.7          0.3           5.7          3.8              1
 20     Iris-setosa           1.5          0.3          51.0          3.8             -1
 21     Iris-setosa           1.7          0.2           5.4          3.4              1
 22     Iris-setosa           1.5          0.4           5.1          3.7              1
 23     Iris-setosa           1.0          0.2           4.6          3.6              1
 24     Iris-setosa           1.7          0.5           5.1          3.3              1
 25     Iris-setosa           1.9          0.2           4.8         34.0             -1
 26     Iris-setosa           1.6          0.2           5.0          3.0              1
 27     Iris-setosa           1.6          0.4           5.0          3.4              1
 28     Iris-setosa           1.5          0.2           5.2          3.5              1
 29     Iris-setosa           1.4          0.2           5.2          3.4              1
 30     Iris-setosa           1.6          0.2          74.0          3.2             -1
 31     Iris-setosa           1.6          0.2           4.8          3.1              1
 32     Iris-setosa           1.5          0.4           5.4          3.4              1
 33     Iris-setosa           1.5          0.1           5.2          4.1              1
 34     Iris-setosa           1.4          0.2           5.5          4.2              1
 35     Iris-setosa           1.5          0.1           4.9         94.0             -1
 36     Iris-setosa           1.2          0.2           5.0          3.2              1
 37     Iris-setosa           1.3          0.2           5.5          3.5              1
 38     Iris-setosa           1.5          0.1           4.9          3.1              1
 39     Iris-setosa           1.3          0.2           4.4          3.0              1
 40     Iris-setosa           1.5          0.2           5.1          3.4              1
 41     Iris-setosa           1.3          0.3           5.0          3.5              1
 42     Iris-setosa           1.3          0.3           4.5          2.3              1
 43     Iris-setosa           1.3          0.2           4.4          3.2              1
 44     Iris-setosa           1.6          0.6           5.0          3.5              1
 45     Iris-setosa           1.9          0.4           5.1          3.8              1
 46     Iris-setosa           1.4          0.3           4.8          3.0              1
 47     Iris-setosa           1.6          0.2           5.1          3.8              1
 48     Iris-setosa           1.4          0.2           4.6          3.2              1
 49     Iris-setosa           1.5          0.2           5.3          3.7              1
 50     Iris-setosa           1.4          0.2           5.0          3.3              1
 51 Iris-versicolor          47.0         14.0          70.0         32.0             -1
 52 Iris-versicolor          45.0         15.0          64.0         32.0             -1
 53 Iris-versicolor          49.0         15.0          69.0         31.0             -1
 54 Iris-versicolor          40.0         13.0          55.0         23.0             -1
 55 Iris-versicolor          46.0         15.0          65.0         28.0             -1
 56 Iris-versicolor           4.5          1.3           5.7          2.8              1
 57 Iris-versicolor           4.7          1.6           6.3          3.3              1
 58 Iris-versicolor           3.3          1.0           4.9          2.4              1
 59 Iris-versicolor           4.6          1.3           6.6          2.9              1
 60 Iris-versicolor           3.9          1.4           5.2          2.7              1
 61 Iris-versicolor           3.5          1.0           5.0          2.0              1
 62 Iris-versicolor           4.2          1.5           5.9          3.0              1
 63 Iris-versicolor           4.0          1.0           6.0          2.2              1
 64 Iris-versicolor           4.7          1.4           6.1          2.9              1
 65 Iris-versicolor           3.6          1.3           5.6          2.9              1
 66 Iris-versicolor           4.4          1.4           6.7          3.1              1
 67 Iris-versicolor           4.5          1.5           5.6          3.0              1
 68 Iris-versicolor           4.1          1.0           5.8          2.7              1
 69 Iris-versicolor           4.5          1.5           6.2          2.2              1
 70 Iris-versicolor           3.9          1.1           5.6          2.5              1
 71 Iris-versicolor           4.8          1.8           5.9          3.2              1
 72 Iris-versicolor           4.0          1.3           6.1          2.8              1
 73 Iris-versicolor           4.9          1.5           6.3          2.5              1
 74 Iris-versicolor           4.7          1.2           6.1          2.8              1
 75 Iris-versicolor           4.3          1.3           6.4          2.9              1
 76 Iris-versicolor           4.4          1.4           6.6          3.0              1
 77 Iris-versicolor           4.8          1.4           6.8          2.8              1
 78 Iris-versicolor           5.0          1.7           6.7          3.0              1
 79 Iris-versicolor           4.5          1.5           6.0          2.9              1
 80 Iris-versicolor           3.5          1.0           5.7          2.6              1
 81 Iris-versicolor           3.8          1.1           5.5          2.4              1
 82 Iris-versicolor           3.7          1.0           5.5          2.4              1
 83 Iris-versicolor           3.9          1.2           5.8          2.7              1
 84 Iris-versicolor           5.1          1.6           6.0          2.7              1
 85 Iris-versicolor           4.5          1.5           5.4          3.0              1
 86 Iris-versicolor           4.5          1.6           6.0          3.4              1
 87 Iris-versicolor           4.7          1.5           6.7          3.1              1
 88 Iris-versicolor           4.4          1.3           6.3          2.3              1
 89 Iris-versicolor           4.1          1.3           5.6          3.0              1
 90 Iris-versicolor           4.0          1.3           5.5          2.5              1
 91 Iris-versicolor           4.4          1.2           5.5          2.6              1
 92 Iris-versicolor           4.6          1.4           6.1          3.0              1
 93 Iris-versicolor           4.0          1.2           5.8          2.6              1
 94 Iris-versicolor           3.3          1.0           5.0          2.3              1
 95 Iris-versicolor           4.2          1.3           5.6          2.7              1
 96 Iris-versicolor           4.2          1.2           5.7          3.0              1
 97 Iris-versicolor           4.2          1.3           5.7          2.9              1
 98 Iris-versicolor           4.3          1.3           6.2          2.9              1
 99 Iris-versicolor           3.0          1.1           5.1          2.5              1
100 Iris-versicolor           4.1          1.3           5.7          2.8              1
101  Iris-virginica          60.0         25.0          63.0         33.0             -1
102  Iris-virginica          51.0         19.0          58.0         27.0             -1
103  Iris-virginica          59.0         21.0          71.0         30.0             -1
104  Iris-virginica          56.0         18.0          63.0         29.0             -1
105  Iris-virginica          58.0         22.0          65.0         30.0             -1
106  Iris-virginica           6.6          2.1           7.6          3.0              1
107  Iris-virginica           4.5          1.7           4.9          2.5              1
108  Iris-virginica           6.3          1.8           7.3          2.9              1
109  Iris-virginica           5.8          1.8           6.7          2.5              1
110  Iris-virginica           6.1          2.5           7.2          3.6              1
111  Iris-virginica           5.1          2.0           6.5          3.2              1
112  Iris-virginica           5.3          1.9           6.4          2.7              1
113  Iris-virginica           5.5          2.1           6.8          3.0              1
114  Iris-virginica           5.0          2.0           5.7          2.5              1
115  Iris-virginica           5.1         42.0           5.8          2.8             -1
116  Iris-virginica           5.3          2.3           6.4          3.2              1
117  Iris-virginica           5.5          1.8           6.5          3.0              1
118  Iris-virginica           6.7          2.2           7.7          3.8              1
119  Iris-virginica           6.9          2.3           7.7          2.6              1
120  Iris-virginica          50.0          1.5           6.0          2.2             -1
121  Iris-virginica           5.7          2.3           6.9          3.2              1
122  Iris-virginica           4.9          2.0           5.6          2.8              1
123  Iris-virginica           6.7          2.0           7.7          2.8              1
124  Iris-virginica           4.9          1.8           6.3          2.7              1
125  Iris-virginica           5.7          2.1           6.7          3.3              1
126  Iris-virginica           6.0         18.0           7.2          3.2             -1
127  Iris-virginica           4.8          1.8           6.2          2.8              1
128  Iris-virginica           4.9          1.8           6.1          3.0              1
129  Iris-virginica           5.6          2.1           6.4          2.8              1
130  Iris-virginica          58.0          1.6           7.2          3.0             -1
131  Iris-virginica           6.1          1.9           7.4          2.8              1
132  Iris-virginica           6.4          2.0           7.9          3.8              1
133  Iris-virginica           5.6          2.2           6.4          2.8              1
134  Iris-virginica           5.1          1.5           6.3          2.8              1
135  Iris-virginica           5.6         41.0           6.1          2.6             -1
136  Iris-virginica           6.1          2.3           7.7          3.0              1
137  Iris-virginica           5.6          2.4           6.3          3.4              1
138  Iris-virginica           5.5          1.8           6.4          3.1              1
139  Iris-virginica           4.8          1.8           6.0          3.0              1
140  Iris-virginica          45.0          2.1           6.9          3.1             -1
141  Iris-virginica           5.6          2.4           6.7          3.1              1
142  Iris-virginica           5.1          2.3           6.9          3.1              1
143  Iris-virginica           5.1          1.9           5.8          2.7              1
144  Iris-virginica           5.9          2.3           6.8          3.2              1
145  Iris-virginica           5.7         25.0           6.7          3.3             -1
146  Iris-virginica           5.2          2.3           6.7          3.0              1
147  Iris-virginica           5.0          1.9           6.3          2.5              1
148  Iris-virginica           5.2          2.0           6.5          3.0              1
149  Iris-virginica           5.4          2.3           6.2          3.4              1
150  Iris-virginica           5.1          1.8           5.9          3.0              1

Jumlah outlier: 28

Data Outlier:
 id           class  petal_length  petal_width  sepal_length  sepal_width
  1     Iris-setosa          14.0          2.0          51.0         35.0
  2     Iris-setosa          14.0          2.0          49.0         30.0
  3     Iris-setosa          13.0          2.0          47.0         32.0
  4     Iris-setosa          15.0          2.0          46.0         31.0
  5     Iris-setosa          14.0          2.0           5.0         36.0
 10     Iris-setosa           1.5          0.1          94.0          3.1
 15     Iris-setosa           1.2          0.2           5.8         40.0
 20     Iris-setosa           1.5          0.3          51.0          3.8
 25     Iris-setosa           1.9          0.2           4.8         34.0
 30     Iris-setosa           1.6          0.2          74.0          3.2
 35     Iris-setosa           1.5          0.1           4.9         94.0
 51 Iris-versicolor          47.0         14.0          70.0         32.0
 52 Iris-versicolor          45.0         15.0          64.0         32.0
 53 Iris-versicolor          49.0         15.0          69.0         31.0
 54 Iris-versicolor          40.0         13.0          55.0         23.0
 55 Iris-versicolor          46.0         15.0          65.0         28.0
101  Iris-virginica          60.0         25.0          63.0         33.0
102  Iris-virginica          51.0         19.0          58.0         27.0
103  Iris-virginica          59.0         21.0          71.0         30.0
104  Iris-virginica          56.0         18.0          63.0         29.0
105  Iris-virginica          58.0         22.0          65.0         30.0
115  Iris-virginica           5.1         42.0           5.8          2.8
120  Iris-virginica          50.0          1.5           6.0          2.2
126  Iris-virginica           6.0         18.0           7.2          3.2
130  Iris-virginica          58.0          1.6           7.2          3.0
135  Iris-virginica           5.6         41.0           6.1          2.6
140  Iris-virginica          45.0          2.1           6.9          3.1
145  Iris-virginica           5.7         25.0           6.7          3.3

Jumlah data setelah dihapus :  122

Data tidak outlier :
 id           class  petal_length  petal_width  sepal_length  sepal_width
  6     Iris-setosa           1.7          0.4           5.4          3.9
  7     Iris-setosa           1.4          0.3           4.6          3.4
  8     Iris-setosa           1.5          0.2           5.0          3.4
  9     Iris-setosa           1.4          0.2           4.4          2.9
 11     Iris-setosa           1.5          0.2           5.4          3.7
 12     Iris-setosa           1.6          0.2           4.8          3.4
 13     Iris-setosa           1.4          0.1           4.8          3.0
 14     Iris-setosa           1.1          0.1           4.3          3.0
 16     Iris-setosa           1.5          0.4           5.7          4.4
 17     Iris-setosa           1.3          0.4           5.4          3.9
 18     Iris-setosa           1.4          0.3           5.1          3.5
 19     Iris-setosa           1.7          0.3           5.7          3.8
 21     Iris-setosa           1.7          0.2           5.4          3.4
 22     Iris-setosa           1.5          0.4           5.1          3.7
 23     Iris-setosa           1.0          0.2           4.6          3.6
 24     Iris-setosa           1.7          0.5           5.1          3.3
 26     Iris-setosa           1.6          0.2           5.0          3.0
 27     Iris-setosa           1.6          0.4           5.0          3.4
 28     Iris-setosa           1.5          0.2           5.2          3.5
 29     Iris-setosa           1.4          0.2           5.2          3.4
 31     Iris-setosa           1.6          0.2           4.8          3.1
 32     Iris-setosa           1.5          0.4           5.4          3.4
 33     Iris-setosa           1.5          0.1           5.2          4.1
 34     Iris-setosa           1.4          0.2           5.5          4.2
 36     Iris-setosa           1.2          0.2           5.0          3.2
 37     Iris-setosa           1.3          0.2           5.5          3.5
 38     Iris-setosa           1.5          0.1           4.9          3.1
 39     Iris-setosa           1.3          0.2           4.4          3.0
 40     Iris-setosa           1.5          0.2           5.1          3.4
 41     Iris-setosa           1.3          0.3           5.0          3.5
 42     Iris-setosa           1.3          0.3           4.5          2.3
 43     Iris-setosa           1.3          0.2           4.4          3.2
 44     Iris-setosa           1.6          0.6           5.0          3.5
 45     Iris-setosa           1.9          0.4           5.1          3.8
 46     Iris-setosa           1.4          0.3           4.8          3.0
 47     Iris-setosa           1.6          0.2           5.1          3.8
 48     Iris-setosa           1.4          0.2           4.6          3.2
 49     Iris-setosa           1.5          0.2           5.3          3.7
 50     Iris-setosa           1.4          0.2           5.0          3.3
 56 Iris-versicolor           4.5          1.3           5.7          2.8
 57 Iris-versicolor           4.7          1.6           6.3          3.3
 58 Iris-versicolor           3.3          1.0           4.9          2.4
 59 Iris-versicolor           4.6          1.3           6.6          2.9
 60 Iris-versicolor           3.9          1.4           5.2          2.7
 61 Iris-versicolor           3.5          1.0           5.0          2.0
 62 Iris-versicolor           4.2          1.5           5.9          3.0
 63 Iris-versicolor           4.0          1.0           6.0          2.2
 64 Iris-versicolor           4.7          1.4           6.1          2.9
 65 Iris-versicolor           3.6          1.3           5.6          2.9
 66 Iris-versicolor           4.4          1.4           6.7          3.1
 67 Iris-versicolor           4.5          1.5           5.6          3.0
 68 Iris-versicolor           4.1          1.0           5.8          2.7
 69 Iris-versicolor           4.5          1.5           6.2          2.2
 70 Iris-versicolor           3.9          1.1           5.6          2.5
 71 Iris-versicolor           4.8          1.8           5.9          3.2
 72 Iris-versicolor           4.0          1.3           6.1          2.8
 73 Iris-versicolor           4.9          1.5           6.3          2.5
 74 Iris-versicolor           4.7          1.2           6.1          2.8
 75 Iris-versicolor           4.3          1.3           6.4          2.9
 76 Iris-versicolor           4.4          1.4           6.6          3.0
 77 Iris-versicolor           4.8          1.4           6.8          2.8
 78 Iris-versicolor           5.0          1.7           6.7          3.0
 79 Iris-versicolor           4.5          1.5           6.0          2.9
 80 Iris-versicolor           3.5          1.0           5.7          2.6
 81 Iris-versicolor           3.8          1.1           5.5          2.4
 82 Iris-versicolor           3.7          1.0           5.5          2.4
 83 Iris-versicolor           3.9          1.2           5.8          2.7
 84 Iris-versicolor           5.1          1.6           6.0          2.7
 85 Iris-versicolor           4.5          1.5           5.4          3.0
 86 Iris-versicolor           4.5          1.6           6.0          3.4
 87 Iris-versicolor           4.7          1.5           6.7          3.1
 88 Iris-versicolor           4.4          1.3           6.3          2.3
 89 Iris-versicolor           4.1          1.3           5.6          3.0
 90 Iris-versicolor           4.0          1.3           5.5          2.5
 91 Iris-versicolor           4.4          1.2           5.5          2.6
 92 Iris-versicolor           4.6          1.4           6.1          3.0
 93 Iris-versicolor           4.0          1.2           5.8          2.6
 94 Iris-versicolor           3.3          1.0           5.0          2.3
 95 Iris-versicolor           4.2          1.3           5.6          2.7
 96 Iris-versicolor           4.2          1.2           5.7          3.0
 97 Iris-versicolor           4.2          1.3           5.7          2.9
 98 Iris-versicolor           4.3          1.3           6.2          2.9
 99 Iris-versicolor           3.0          1.1           5.1          2.5
100 Iris-versicolor           4.1          1.3           5.7          2.8
106  Iris-virginica           6.6          2.1           7.6          3.0
107  Iris-virginica           4.5          1.7           4.9          2.5
108  Iris-virginica           6.3          1.8           7.3          2.9
109  Iris-virginica           5.8          1.8           6.7          2.5
110  Iris-virginica           6.1          2.5           7.2          3.6
111  Iris-virginica           5.1          2.0           6.5          3.2
112  Iris-virginica           5.3          1.9           6.4          2.7
113  Iris-virginica           5.5          2.1           6.8          3.0
114  Iris-virginica           5.0          2.0           5.7          2.5
116  Iris-virginica           5.3          2.3           6.4          3.2
117  Iris-virginica           5.5          1.8           6.5          3.0
118  Iris-virginica           6.7          2.2           7.7          3.8
119  Iris-virginica           6.9          2.3           7.7          2.6
121  Iris-virginica           5.7          2.3           6.9          3.2
122  Iris-virginica           4.9          2.0           5.6          2.8
123  Iris-virginica           6.7          2.0           7.7          2.8
124  Iris-virginica           4.9          1.8           6.3          2.7
125  Iris-virginica           5.7          2.1           6.7          3.3
127  Iris-virginica           4.8          1.8           6.2          2.8
128  Iris-virginica           4.9          1.8           6.1          3.0
129  Iris-virginica           5.6          2.1           6.4          2.8
131  Iris-virginica           6.1          1.9           7.4          2.8
132  Iris-virginica           6.4          2.0           7.9          3.8
133  Iris-virginica           5.6          2.2           6.4          2.8
134  Iris-virginica           5.1          1.5           6.3          2.8
136  Iris-virginica           6.1          2.3           7.7          3.0
137  Iris-virginica           5.6          2.4           6.3          3.4
138  Iris-virginica           5.5          1.8           6.4          3.1
139  Iris-virginica           4.8          1.8           6.0          3.0
141  Iris-virginica           5.6          2.4           6.7          3.1
142  Iris-virginica           5.1          2.3           6.9          3.1
143  Iris-virginica           5.1          1.9           5.8          2.7
144  Iris-virginica           5.9          2.3           6.8          3.2
146  Iris-virginica           5.2          2.3           6.7          3.0
147  Iris-virginica           5.0          1.9           6.3          2.5
148  Iris-virginica           5.2          2.0           6.5          3.0
149  Iris-virginica           5.4          2.3           6.2          3.4
150  Iris-virginica           5.1          1.8           5.9          3.0
</pre></div>
</div>
</div>
</div>
<p>Kode ini mengambil data dari PostgreSQL dan MySQL, lalu menggabungkannya berdasarkan kolom <strong>“id”</strong> dan <strong>“class”</strong>. Setelah itu, digunakan algoritma <strong>Local Outlier Factor (LOF)</strong> dengan <strong>90 tetangga terdekat</strong> untuk mendeteksi outlier berdasarkan fitur numerik <strong>(petal_length, petal_width, sepal_length, sepal_width)</strong>. Data yang memiliki label <strong>-1</strong> dianggap sebagai outlier, sementara data dengan label <strong>1</strong> dianggap normal. Hasilnya ditampilkan dalam dua kelompok: <strong>data outlier</strong> dan <strong>data yang tidak outlier</strong>, beserta jumlahnya setelah outlier dihapus.</p>
</section>
<section id="menghitung-akurasi">
<h3>Menghitung Akurasi<a class="headerlink" href="#menghitung-akurasi" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Menerapkan LOF untuk deteksi outlier</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">outlier_labels</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_labels</span>

<span class="c1"># Pisahkan data dengan outlier dan tanpa outlier</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">])</span>

<span class="c1"># Membagi data menjadi training (80%) dan testing (20%)</span>
<span class="n">X_train_all</span><span class="p">,</span> <span class="n">X_test_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">,</span> <span class="n">y_test_all</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_encoded</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="n">X_train_clean</span><span class="p">,</span> <span class="n">X_test_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">,</span> <span class="n">y_test_clean</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">],</span>
    <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]),</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Pipeline dengan StandardScaler dan KNN</span>
<span class="n">knn_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Latih model pada data dengan outlier</span>
<span class="n">knn_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">)</span>
<span class="n">y_pred_all</span> <span class="o">=</span> <span class="n">knn_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_all</span><span class="p">)</span>
<span class="n">accuracy_all</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi dengan outlier:&quot;</span><span class="p">,</span> <span class="n">accuracy_all</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>

<span class="c1"># Latih model pada data tanpa outlier</span>
<span class="n">knn_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">)</span>
<span class="n">y_pred_clean</span> <span class="o">=</span> <span class="n">knn_pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_clean</span><span class="p">)</span>
<span class="n">accuracy_clean</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi tanpa outlier:&quot;</span><span class="p">,</span> <span class="n">accuracy_clean</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi dengan outlier: 0.8666666666666667
                 precision    recall  f1-score   support

    Iris-setosa       1.00      0.70      0.82        10
Iris-versicolor       0.82      1.00      0.90         9
 Iris-virginica       0.83      0.91      0.87        11

       accuracy                           0.87        30
      macro avg       0.88      0.87      0.86        30
   weighted avg       0.88      0.87      0.86        30

Akurasi tanpa outlier: 1.0
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        13
Iris-versicolor       1.00      1.00      1.00         6
 Iris-virginica       1.00      1.00      1.00         8

       accuracy                           1.00        27
      macro avg       1.00      1.00      1.00        27
   weighted avg       1.00      1.00      1.00        27
</pre></div>
</div>
</div>
</div>
<p>Kode ini melakukan <strong>deteksi outlier</strong> menggunakan <strong>Local Outlier Factor (LOF)</strong> dan mengevaluasi dampaknya terhadap <strong>akurasi model K-Nearest Neighbors (KNN)</strong> dalam klasifikasi data <strong>Iris</strong>. Pertama, fitur numerik <strong>(X)</strong> dan label kelas <strong>(y)</strong> diekstrak dari data, lalu label kelas dikonversi ke bentuk numerik dengan <strong>LabelEncoder</strong>. LOF diterapkan untuk mengidentifikasi <strong>outlier</strong>, di mana data dengan label <strong>-1</strong> dianggap sebagai outlier dan dihapus, sehingga terbentuk <strong>df_cleaned</strong> (data tanpa outlier). Data kemudian dibagi menjadi <strong>80% training dan 20% testing</strong>, baik untuk data asli (dengan outlier) maupun data yang telah dibersihkan dari outlier. Model <strong>KNN dengan k=11</strong> diterapkan menggunakan <strong>pipeline yang mencakup StandardScaler</strong>, lalu dilatih dan dievaluasi pada kedua versi data. Hasil evaluasi menunjukkan perbandingan <strong>akurasi sebelum dan sesudah menghapus outlier</strong>, dengan <strong>classification_report</strong> yang memberikan metrik klasifikasi seperti precision, recall, dan f1-score.</p>
</section>
<section id="visualisasi">
<h3>Visualisasi<a class="headerlink" href="#visualisasi" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">DecisionBoundaryDisplay</span>

<span class="c1"># Ambil dua fitur utama untuk visualisasi decision boundary</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;petal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;petal_width&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Ubah nama kelas jadi angka</span>

<span class="c1"># Membagi data menjadi training (80%) dan testing (20%)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y_encoded</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Pipeline dengan KNN dan StandardScaler</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Pelatihan model KNN</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluasi model</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>

<span class="c1"># Visualisasi Decision Boundary</span>
<span class="n">_</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">weights</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="s2">&quot;distance&quot;</span><span class="p">)):</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">knn__weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">disp</span> <span class="o">=</span> <span class="n">DecisionBoundaryDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
        <span class="n">clf</span><span class="p">,</span>
        <span class="n">X_test</span><span class="p">,</span>
        <span class="n">response_method</span><span class="o">=</span><span class="s2">&quot;predict&quot;</span><span class="p">,</span>
        <span class="n">plot_method</span><span class="o">=</span><span class="s2">&quot;pcolormesh&quot;</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">shading</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">scatter</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span>
    <span class="p">)</span>
    <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
        <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower left&quot;</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Classes&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;3-Class classification</span><span class="se">\n</span><span class="s2">(k=</span><span class="si">{</span><span class="n">clf</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">, weights=</span><span class="si">{</span><span class="n">weights</span><span class="si">!r}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi: 1.0
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        13
Iris-versicolor       1.00      1.00      1.00         6
 Iris-virginica       1.00      1.00      1.00         8

       accuracy                           1.00        27
      macro avg       1.00      1.00      1.00        27
   weighted avg       1.00      1.00      1.00        27
</pre></div>
</div>
<img alt="_images/bfc8cab30fd45e3ea376dc2ee616ce39cd162b567e9c757474310470c79a2b32.png" src="_images/bfc8cab30fd45e3ea376dc2ee616ce39cd162b567e9c757474310470c79a2b32.png" />
</div>
</div>
<p>Kode ini melakukan klasifikasi menggunakan algoritma K-Nearest Neighbors (KNN) dengan dua fitur utama (petal_length dan petal_width) dari dataset yang sudah dibersihkan dari outlier. Data terlebih dahulu diencode menggunakan LabelEncoder, lalu dibagi menjadi 80% training dan 20% testing. Model KNN diterapkan dalam pipeline bersama StandardScaler untuk menstandarisasi data, kemudian dilatih dengan 11 tetangga terdekat (n_neighbors=11). Evaluasi model dilakukan dengan akurasi dan classification report. Terakhir, kode membuat visualisasi decision boundary dari model KNN dengan dua skenario pembobotan (uniform dan distance), menggunakan DecisionBoundaryDisplay untuk menggambarkan bagaimana model membedakan kelas berdasarkan fitur yang dipilih.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">pymysql</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">DecisionBoundaryDisplay</span>


<span class="c1"># Ambil dua fitur utama untuk visualisasi decision boundary</span>
<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sepal_length&quot;</span><span class="p">,</span> <span class="s2">&quot;sepal_width&quot;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Mengubah nama kelas menjadi angka</span>

<span class="c1"># Menerapkan LOF untuk deteksi outlier</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">outlier_labels</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlier_labels</span>

<span class="c1"># Menghapus data yang terdeteksi sebagai outlier</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">])</span>

<span class="c1"># Membagi data menjadi training (80%) dan testing (20%)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">],</span>
    <span class="n">label_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">]),</span>  <span class="c1"># Pastikan target dalam bentuk numerik</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Pipeline dengan KNN dan StandardScaler</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
    <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span>
    <span class="p">(</span><span class="s2">&quot;knn&quot;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">11</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Pelatihan model KNN</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluasi model</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">))</span>

<span class="c1"># Visualisasi Decision Boundary</span>
<span class="n">_</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">weights</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span> <span class="s2">&quot;distance&quot;</span><span class="p">)):</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">knn__weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">disp</span> <span class="o">=</span> <span class="n">DecisionBoundaryDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
        <span class="n">clf</span><span class="p">,</span>
        <span class="n">X_test</span><span class="p">,</span>
        <span class="n">response_method</span><span class="o">=</span><span class="s2">&quot;predict&quot;</span><span class="p">,</span>
        <span class="n">plot_method</span><span class="o">=</span><span class="s2">&quot;pcolormesh&quot;</span><span class="p">,</span>
        <span class="n">xlabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">ylabel</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">shading</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">scatter</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">c</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;viridis&quot;</span>
    <span class="p">)</span>
    <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span>
        <span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span>
        <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower left&quot;</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Classes&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">disp</span><span class="o">.</span><span class="n">ax_</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;3-Class classification</span><span class="se">\n</span><span class="s2">(k=</span><span class="si">{</span><span class="n">clf</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">n_neighbors</span><span class="si">}</span><span class="s2">, weights=</span><span class="si">{</span><span class="n">weights</span><span class="si">!r}</span><span class="s2">)&quot;</span>
    <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi: 0.7037037037037037
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00         9
Iris-versicolor       0.62      0.50      0.56        10
 Iris-virginica       0.50      0.62      0.56         8

       accuracy                           0.70        27
      macro avg       0.71      0.71      0.70        27
   weighted avg       0.71      0.70      0.70        27
</pre></div>
</div>
<img alt="_images/337ad6819f1e20773733373e87dc27dd05607c52cb7a047636a1f3f257ba6e89.png" src="_images/337ad6819f1e20773733373e87dc27dd05607c52cb7a047636a1f3f257ba6e89.png" />
</div>
</div>
<p>Kode ini melakukan deteksi outlier dengan LOF dan klasifikasi dengan KNN menggunakan fitur sepal_length dan sepal_width. Pertama, data dikodekan menggunakan LabelEncoder, lalu outlier diidentifikasi dengan Local Outlier Factor (LOF) menggunakan 20 tetangga (n_neighbors=20) dan 10% data dianggap outlier (contamination=0.1). Data yang terdeteksi sebagai outlier dihapus sebelum digunakan dalam pembagian data training (80%) dan testing (20%). Model KNN dengan 11 tetangga (n_neighbors=11) diterapkan dalam pipeline bersama StandardScaler, lalu dilatih dan dievaluasi menggunakan akurasi dan classification report. Terakhir, kode membuat visualisasi decision boundary dengan dua skenario bobot (uniform dan distance), menunjukkan bagaimana model memisahkan kelas berdasarkan fitur yang dipilih.</p>
</section>
</section>
<section id="klasifikasi-dengan-naive-baiyes">
<h2>Klasifikasi  Dengan Naive Baiyes<a class="headerlink" href="#klasifikasi-dengan-naive-baiyes" title="Link to this heading">#</a></h2>
<section id="menyiapkan-data">
<h3>Menyiapkan Data<a class="headerlink" href="#menyiapkan-data" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># Encode label kelas ke numerik</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class_encoded&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">])</span>

<span class="c1"># Data dengan outlier</span>
<span class="n">X_all</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y_all</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;class_encoded&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Pastikan dalam bentuk array numpy</span>

<span class="c1"># Data tanpa outlier</span>
<span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df_merged</span><span class="p">[</span><span class="n">df_merged</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;outlier&quot;</span><span class="p">])</span>
<span class="n">X_clean</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="n">feature_columns</span><span class="p">]</span>
<span class="n">y_clean</span> <span class="o">=</span> <span class="n">df_cleaned</span><span class="p">[</span><span class="s2">&quot;class_encoded&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Pastikan dalam bentuk array numpy</span>
</pre></div>
</div>
</div>
</div>
<p>Kode ini mengonversi label kelas menjadi numerik menggunakan LabelEncoder() agar dapat digunakan dalam model machine learning. Setelah itu, dataset dibagi menjadi dua bagian: satu dengan outlier dan satu tanpa outlier. Dataset dengan outlier disimpan dalam X_all untuk fitur dan y_all untuk label kelas yang telah dikonversi. Sementara itu, dataset tanpa outlier difilter dengan hanya menyertakan baris di mana outlier == 1, lalu kolom outlier dihapus. Data hasil pembersihan ini disimpan dalam X_clean untuk fitur dan y_clean untuk label kelas dalam bentuk numerik, memastikan bahwa analisis dapat dilakukan baik dengan maupun tanpa outlier.</p>
</section>
<section id="pelatihan-pengujian-dan-evaluasi-model-naive-bayes">
<h3>Pelatihan, Pengujian, dan Evaluasi Model Naïve Bayes<a class="headerlink" href="#pelatihan-pengujian-dan-evaluasi-model-naive-bayes" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Split data dengan outlier</span>
<span class="n">X_train_all</span><span class="p">,</span> <span class="n">X_test_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">,</span> <span class="n">y_test_all</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_all</span><span class="p">,</span> <span class="n">y_all</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Split data tanpa outlier</span>
<span class="n">X_train_clean</span><span class="p">,</span> <span class="n">X_test_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">,</span> <span class="n">y_test_clean</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_clean</span><span class="p">,</span> <span class="n">y_clean</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Inisialisasi model Naive Bayes</span>
<span class="n">gnb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1"># Latih dan uji model dengan outlier</span>
<span class="n">y_pred_all</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_all</span><span class="p">,</span> <span class="n">y_train_all</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_all</span><span class="p">)</span>
<span class="n">accuracy_all</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">)</span>

<span class="c1"># Latih dan uji model tanpa outlier</span>
<span class="n">y_pred_clean</span> <span class="o">=</span> <span class="n">gnb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_clean</span><span class="p">,</span> <span class="n">y_train_clean</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_clean</span><span class="p">)</span>
<span class="n">accuracy_clean</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">)</span>

<span class="c1"># Evaluasi model dengan outlier</span>
<span class="n">mislabeled_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_test_all</span> <span class="o">!=</span> <span class="n">y_pred_all</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah data yang salah diklasifikasikan dengan outlier dari total </span><span class="si">%d</span><span class="s2"> data : </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test_all</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mislabeled_all</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi dengan outlier: </span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy_all</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>

<span class="c1"># Menampilkan label yang salah pada data dengan outlier</span>
<span class="n">mislabeled_indices_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test_all</span> <span class="o">!=</span> <span class="n">y_pred_all</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data yang salah diklasifikasikan dengan outlier:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">mislabeled_indices_all</span><span class="p">:</span>
    <span class="n">true_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_pred_all</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Indeks: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, Label Asli: </span><span class="si">{</span><span class="n">true_label</span><span class="si">}</span><span class="s2">, Prediksi: </span><span class="si">{</span><span class="n">predicted_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="c1"># Evaluasi model tanpa outlier</span>
<span class="n">mislabeled_clean</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_test_clean</span> <span class="o">!=</span> <span class="n">y_pred_clean</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah data yang salah diklasifikasikan tanpa outlier dari total </span><span class="si">%d</span><span class="s2"> data : </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_test_clean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mislabeled_clean</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi tanpa outlier: </span><span class="si">%.2f%%</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy_clean</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>

<span class="c1"># Menampilkan label yang salah pada data tanpa outlier</span>
<span class="n">mislabeled_indices_clean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_test_clean</span> <span class="o">!=</span> <span class="n">y_pred_clean</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data yang salah diklasifikasikan tanpa outlier:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">mislabeled_indices_clean</span><span class="p">:</span>
    <span class="n">true_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">y_pred_clean</span><span class="p">[</span><span class="n">i</span><span class="p">])])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Indeks: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, Label Asli: </span><span class="si">{</span><span class="n">true_label</span><span class="si">}</span><span class="s2">, Prediksi: </span><span class="si">{</span><span class="n">predicted_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah data yang salah diklasifikasikan dengan outlier dari total 30 data : 19
Akurasi dengan outlier: 36.67%
Data yang salah diklasifikasikan dengan outlier:
Indeks: 0, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 2, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 3, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 4, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 6, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 7, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 8, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 9, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 10, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 15, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 17, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 18, Label Asli: Iris-versicolor, Prediksi: Iris-setosa
Indeks: 19, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 21, Label Asli: Iris-virginica, Prediksi: Iris-setosa
Indeks: 23, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 24, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 25, Label Asli: Iris-virginica, Prediksi: Iris-versicolor
Indeks: 26, Label Asli: Iris-virginica, Prediksi: Iris-setosa
Indeks: 27, Label Asli: Iris-virginica, Prediksi: Iris-versicolor

Jumlah data yang salah diklasifikasikan tanpa outlier dari total 27 data : 0
Akurasi tanpa outlier: 100.00%
Data yang salah diklasifikasikan tanpa outlier:
</pre></div>
</div>
</div>
</div>
<p>Kode ini melakukan evaluasi model Naïve Bayes pada dataset dengan dan tanpa outlier untuk membandingkan akurasi klasifikasinya. Pertama, dataset dibagi menjadi data latih dan data uji menggunakan train_test_split, baik untuk data yang mengandung outlier maupun yang telah dibersihkan dari outlier. Model Naïve Bayes (GaussianNB) kemudian dilatih dan diuji pada kedua versi dataset, dengan hasil prediksi dibandingkan dengan label sebenarnya menggunakan metrik accuracy_score. Jumlah data yang salah diklasifikasikan dihitung dan ditampilkan untuk kedua skenario, serta akurasinya dalam persentase. Selain itu, kode juga mengidentifikasi dan mencetak indeks serta label dari data yang diklasifikasikan secara salah dalam kedua kondisi, dengan menerjemahkan label numerik kembali ke bentuk aslinya menggunakan LabelEncoder. Tujuan dari proses ini adalah untuk memahami dampak keberadaan outlier terhadap performa model, di mana hasil akhirnya menunjukkan perbandingan akurasi dan jumlah kesalahan klasifikasi dengan dan tanpa outlier.</p>
</section>
<section id="visualisasi-confussion-matrix">
<h3>Visualisasi Confussion Matrix<a class="headerlink" href="#visualisasi-confussion-matrix" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Confusion Matrix dengan outlier</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_all</span><span class="p">,</span> <span class="n">y_pred_all</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix with Outliers&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>

<span class="c1"># Confusion Matrix tanpa outlier</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_clean</span><span class="p">,</span> <span class="n">y_pred_clean</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix without Outliers&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Label&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;True Label&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f23e4c415f7cc8a6b81a38800c966b1363d0145a27454e441ce38025424f0f2c.png" src="_images/f23e4c415f7cc8a6b81a38800c966b1363d0145a27454e441ce38025424f0f2c.png" />
</div>
</div>
<p>Kode ini bertujuan untuk memvisualisasikan performa model Naïve Bayes menggunakan confusion matrix dalam dua kondisi: dengan dan tanpa outlier. Menggunakan matplotlib dan seaborn, dua confusion matrix dibuat dalam satu figure dengan dua subplot yang bersebelahan. Masing-masing confusion matrix menggambarkan perbandingan antara label sebenarnya (y_test_all atau y_test_clean) dengan hasil prediksi model (y_pred_all atau y_pred_clean). Warna biru digunakan untuk memperjelas jumlah prediksi dalam tiap kategori, dan nilai prediksi ditampilkan dalam setiap sel menggunakan annot=True. Sumbu horizontal merepresentasikan label yang diprediksi, sementara sumbu vertikal menunjukkan label sebenarnya. Dengan visualisasi ini, kita dapat melihat pola kesalahan klasifikasi dan membandingkan bagaimana keberadaan outlier mempengaruhi kinerja model.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="pendat1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Data UnderStanding</p>
      </div>
    </a>
    <a class="right-next"
       href="uts.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">UTS PENDAT</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-outlier">Deteksi Outlier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tahap-deteksi-outlier-dengan-knn">Tahap Deteksi Outlier dengan KNN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">Kesimpulan</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#local-outlier-factor-lof">Local Outlier Factor (LOF)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tahapan-lof">Tahapan LOF</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengitung-manual">Mengitung Manual</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-lof-menggunakan-scikit-learn">Implementasi LOF menggunakan Scikit-Learn</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-knn">Klasifikasi Dengan KNN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memisahkan-outlier-dari-data">Memisahkan Outlier Dari Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menghitung-akurasi">Menghitung Akurasi</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi">Visualisasi</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-dengan-naive-baiyes">Klasifikasi  Dengan Naive Baiyes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menyiapkan-data">Menyiapkan Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pelatihan-pengujian-dan-evaluasi-model-naive-bayes">Pelatihan, Pengujian, dan Evaluasi Model Naïve Bayes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualisasi-confussion-matrix">Visualisasi Confussion Matrix</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Vania Putri
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>